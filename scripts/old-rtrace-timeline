#!/usr/bin/env python

# Copyright (C) 2010 by Nokia Corporation
#
# Contact: Eero Tamminen <eero.tamminen@nokia.com>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License 
# version 2 as published by the Free Software Foundation. 
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301 USA

import sys, string, re, os, getopt, subprocess, operator

class Timestamp:
	"""
	This class provides timestamp utility functions.
	"""
	rxpTimestamp = re.compile("^([0-9]+)\:([0-9]+)\:([0-9]+)\.([0-9]+)$")

	def toString(hours, decimal = 3):
		"Converts integer timestamp (milliseconds since midnight) to text format HH:MM:SS.sss"
		msecs = hours % 1000		
		hours /= 1000
		seconds = hours % 60
		hours /= 60
		minutes = hours % 60
		hours /= 60  
		timestamp = "%02d:%02d:%02d" % (hours, minutes, seconds)
		if decimal > 0:
			for i in range (3 - decimal):
				msecs /= 10
			mask = ".%%0%dd" % decimal
			timestamp += mask % msecs
		return timestamp
	
	toString = staticmethod(toString)
	
	def offsetToString(offset):
		"Converts timestamp offset (milliseconds) to text format +[HH:][MM:][SS][.sss]"
		text = Timestamp.toString(offset)
		text = string.lstrip(text, ":0")
		text = string.rstrip(text, "0")
		if text[-1] == '.':
			text = string.rstrip(text, ".")
		if text == "" or text[0] == '.':
			text = "0" + text
		return text
	
	offsetToString = staticmethod(offsetToString)
	
	def fromString(text):
		"Converts text format timestamp HH:MM:SS.sss into integer value (milliseconds since midnight)"
		timestamp = 0
		match = Timestamp.rxpTimestamp.match(text)
		if match:
			timestamp = int(match.group(1)) * 3600000 + int(match.group(2)) * 60000 + int(match.group(3)) * 1000 + int(match.group(4))
		return timestamp

	fromString = staticmethod(fromString)
# /class Timestamp


class Context:
	"""
	This class contains allocation context implementation.
	"""
	# context masks 
	MASK_NONE = 0
	MASK_ALL = 0xFFFFFFFF
	
	# the context value/mask
	value = 0
	# the context name
	name = ""

	def __init__(self, value, name):
		self.value = value
		self.name = name

	def isMaskAll(self):
		"Checks if the context value covers all allocations ignoring their context"
		return self.value == Context.MASK_ALL
	
	def isMaskNone(self):
		"Checks if the context value is empty, masking allocations without contexts"
		return self.value == Context.MASK_NONE
# /class Context


class Resource:
	"""
	This class describes the tracked resource type.
	"""
	
	# the resource name
	type = None
	# flag indicating that reference counting mechanism is used for resource allocations
	refCounted = False
	
	def __init__(self, type, refCounted):
		self.type = type
		self.refCounted = refCounted
# /class Resource		

class Event:
	"""
	This class contains allocation/deallocation call event implementation.
	"""
	class Types:
		UNDEFINED = 0
		ALLOC = 1  
		FREE = 2
	# /class Types
		
	timestamp = 0
	res_size = 0
	res_id = 0
	type = Types.UNDEFINED
	context = 0
	index = 0
	
	def __init__(self, type, index, context, timestamp, res_id, res_size):
		self.type = type
		self.timestamp = timestamp
		self.res_size = res_size
		self.res_id = res_id
		self.context = context
		self.index = index
		
	def matchContext(self, context):
		"Checks if the event matches the specified context"
		if context.isMaskNone():
			if self.context != 0:
				return False
		elif not (context.isMaskAll() or (context.value & int(self.context, 16))):
			return False
		return True
# /class Event

class Filter:
	"""
	The base class for event filters.
	"""

	def matchesEvent(self, event):
		"Checks if the filter matches the event"
		return False
	
# /class Filter


class MinTimeFilter:
	"""
	Minimal event time filter, matching events with timestamp greater or equal.
	"""
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.timestamp >= self.value
# /class MinTimeFilter


class MaxTimeFilter:
	"""
	Maximal event time filter, matching events with timestamp less or equal.
	"""
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.timestamp <= self.value
# /class MaxTimeFilter


class MinTimeOffsetFilter:
	"""
	Minimal event time offset filter, matching events with relative timestamp greater or equal.
	The relative timestamp is counted from the first timestamp matching previous filters.
	"""
	value = 0
	offset = None
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		if self.offset is None:
			self.offset = event.timestamp
		return event.timestamp >= self.value + self.offset
# /class MinTimeOffsetFilter


class MaxTimeOffsetFilter:
	"""
	Maximal event time offset filter, matching events with relative tiemstamp less or equal.
	The relative timestamp is counted from the first timestamp matching previous filters.
	Practically it means log duration.
	"""
	value = 0
	offset = None
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		if self.offset is None:
			self.offset = event.timestamp
		return event.timestamp <= self.value + self.offset
# /class MaxTimeOffsetFilter

 
class MinSizeFilter(Filter):
	"""
	Minimal resource size filter, matching events with resource size grater or equal.
	"""		
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.type == Event.Types.FREE or event.res_size >= self.value
# /class MinSizeFilter		


class MaxSizeFilter(Filter):
	"""
	Maximal resource size filter, matching events with resource size less or equal.
	"""		
	value = 0
		
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.type == Event.Types.FREE or event.res_size <= self.value
# /class MaxSizeFilter		


class MinIndexFilter(Filter):
	"""
	Minimal event index filter, matching events with call record index greater or equal.
	"""		
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.index >= self.value
# /class MinIndexFilter		


class MaxIndexFilter(Filter):
	"""
	Maximal event index filter, matching events with call record index less or equal.
	"""		
	value = 0
		
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.index <= self.value
# /class MaxIndexFilter		
			
class ContextFilter(Filter):
	"""
	Context filter, matching events with allocation context mathching the specified context.
	"""			
	value = 0
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return (self.value == 0 and event.context == 0) or (self.value & int(event.context))
# /class ContextFilter	
			
class Tic:
	"""
	This class provides helper functions for time slices used to represent
	time tics and activity slices.
	"""
	value = 0
	format = None
	text = None
	decimal = 0
		
	def __init__(self, slice, rounded):
		if rounded:
			round = 1
			value = slice
			self.value = 1
			while value != 0:
				self.value = value * round;
				round *= 10
				value /= 10
			#
		else: 
			self.value = slice
			
		self.decimal = 3
		slice = self.value
		while self.decimal and slice and slice % 10 == 0:
			self.decimal -= 1
			slice /= 10	
		self.format = "%%.%df" % self.decimal
	
	def getText(self):
		"Returns tic value converted into text format"
		if not self.text:
			self.text = self.format % (float(self.value) / 1000)
		return self.text	
	
# /class Tic

class Terminal:
	"""
	The base lass for terminal types.
	"""

	def init(self, file):
		"Writes terminal initialization data into configuration file"
		raise NotImplementedError()
	
	def finish(self, file):
		"Writes terminal uninitialization data into configuration file"
# /class Terminal	


class EpsTerminal(Terminal):
	"""
	Generates encapsulated postscrpipt file containing graphs
	"""
	
	def init(selfself, file):
		file.write("set terminal postscript eps enhanced color size %d,%d\n" % (Options.scaleX * 6, Options.scaleY * 4))
# /class PostscriptTerminal


class PngTerminal(Terminal):
	"""
	Generates png file containing graphs.
	"""

	def init(selfself, file):
		file.write("set terminal png enhanced size %d,%d\n" % (Options.scaleX * 1024, Options.scaleY * 728))
		file.write("set fontpath \"/usr/share/fonts/truetype/ttf-liberation\"\n")
# /class PostscriptTerminal
		

class WxtTerminal(Terminal):
	"""
	Displays output in a separate window ctreated by wxWidgets library.
	"""
	
	def init(self, file):
		file.write("set terminal wxt enhanced size 1024,728\n")
		
	def finish(self, file):
		file.write("pause -1 \"The graph is displayed in other window. Hit enter when you are finished viewing it...\\n\"\n")
# /class WxtTerminal

	
class Plotter:
	"""
	The plotter class provides high level API for creating gnuplot configuration file.
	
	The configuration file is created when creating Plotter instance and closed
	when the plot() method is called().
	"""
	
	class Table:
		"""
		The Table class provides table emulation with gnuplot labels.
		"""
		
		class Column:
			"""
			The Column class represents a single column in the table.
			"""
			
			class Cell:
				"""
				The Cell class represents a single cell in the column.
				"""
				text = None
				align = None
				
				def __init__(self, text, align = "right"):
					self.text = text
					self.align = align
		
				def write(self, file, row, col, size):
					"Writes cell contents at the specified coordinates"
					if self.align == "right":
						col += size - 1
					if self.align == "center":
						col += size / 2
					file.write("set label \"%s\" at character %d,%d %s\n" % (self.text, col, row, self.align))
				# /class Cell
			
			size = 0
			cells = None
			
			def __init__(self, size):
				self.size = size	
				self.cells = []
				
			def setCell(self, row, text, align):
				"Sets new cell containing text at the specified row"
				if row + 1 > len(self.cells):
					self.cells.extend(None for rows in range(row + 1 - len(self.cells)))
				self.cells[row] = self.Cell(text, align)
			
			def write(self, file, rows, col):
				"Writes column contents at the specified coordinates"
				for row in range(len(self.cells)):
					cell = self.cells[row]
					if cell is None:
						continue
					cell.write(file, rows - row, col, self.size)
				return self.size
		# /class Column
			
		rows = 0
		columns = None
		
		def __init__(self, row, col):
			self.row = row
			self.col = col
			self.columns = []
		
		def addColumn(self, width):
			"Adds a new column of the specified width"
			self.columns.append(self.Column(width))
		
		def setText(self, row, col, text, align = "right"):
			"Sets value of the cell at row,col with text"
			if col > len(self.columns):
				raise RuntimeError("Table.setText: column value(%d) exceeding column count(%d)" % (col, len(self.columns)))
			self.columns[col].setCell(row, text, align)
			if row > self.rows:
				self.rows = row
			
		def write(self, file):
			"Writes table into gnulot configuration file"
			offset = self.col
			for column in self.columns:
				offset += column.write(file, self.rows + self.row, offset)
	# /class Table
		
	class DataFile:
		"""
		This class represents gnuplot data file.
		"""
		
		# the target file name
		_filename = None
		
		def __init__(self, filename, title = None):
			self._filename = filename
			if title:
				self.create(title)
			
		def create(self, title = None):
			"Creates data file and write title if specified"
			self.file = open(self._filename, "w")
			if self.file is None:
				raise RuntimeError("Failed to create data file: %s" % filename)
			if title:
				self.file.write("Resource \"%s\"\n" % title)
			
		def write(self, x, y):
			"Writes a single graph point into data file"
			self.file.write("%d %d\n" % (x, y))
			
		def writeSeparator(self):
			self.file.write("\n")
			
		def writeText(self, value):
			"Writes text data into data file"
			self.file.write(value)
			
		def close(self):
			"Closes the file"
			self.file.close()
			
		def remove(self):
			"Deletes the target file"
			if os.path.isfile(self._filename):
				os.remove(self._filename)
			
		def getFilename(self):
			"Retrieves name of the target file"
			return self._filename
	# /class DataFile
	
	# the configuration file
	file = None
	# the tables to plot
	tables = None
	# the involved data files
	files = None
	# the output stream
	stream = None
	# the graphs to plot. Usually there is a one data file for one graph
	graphs = None
	# the last index of line style setting
	lineStyleIndex = 0
	# the plot id
	id = None
	# configuration file name
	cfgFilename = None
		
	def __init__(self, id):
		# initialize list values
		self.tables = []
		self.files = []
		self.graphs = []
		self.id = id
		self.cfgFilename = "timeline-%s.cfg" % id 
		
	def create(self):
		"Creates gnuplot configuration file"
		self.file = open(self.cfgFilename, "w")
		if self.file is None:
			print >> sys.stderr, "Failed to create configuration file: %s" % self.cfgFilename
			sys.exit(2)
	
		# initialize output terminal
		Options.terminal.init(self.file)

		self.stream = open("%s-%s%s" % (Options.outFilename, self.id, Options.outExtension), "w")
		
		# write graph legend outside graph
		self.file.write("set key bmargin\n")
		
	def setTitle(self, title):
		"Sets report title. The report title is printed at the top of the graph."
		self.file.write("set title \"%s" % title)
		if Options.filterString:
			self.file.write("\\n(%s)" % Options.filterString)
		self.file.write("\"\n")
		
	def setStyle(self, style):
		self.file.write("set style %s\n" % style)

	def setAxisX(self, label, min = None, max = None, format = None, scale = None):
		"Sets X axis range (min-max) and formatting."

		# set ticks
		self.file.write("set xtics rotate nomirror\n")
		if scale:
			self.file.write("set xtics scale %s\n" % scale)
			
		if min:
			if min == max:
				max += 1
			range = max - min
			step = Tic(range / 10, True)
			tic = min - min % step.value
			if min % step.value > 0:
				tic += step.value
			min = tic
			
			# set label
			self.file.write("set xlabel \"%s\" offset 0,0\n" % label)
			# set  range
			self.file.write("set xrange[%d:%d]\n" % (min, max))
			# set the X axis tic label format, not used as tics are printed manually
			# file.write("set format x \"+%.3f\"\n")
	
			# place autotics outside range to avoid interference with manual tics
			self.file.write("set xtics %f,%f\n" % (max * 2, max * 2))
			
			while tic <= max - step.value:
				self.file.write("set xtics add (\"%s\\n+%s\" %d)\n" % (Timestamp.toString(tic, step.decimal), Timestamp.offsetToString(tic - min), tic))
				tic += step.value
			self.file.write("set xtics add (\"%s\\n+%s\" %d)\n" % (Timestamp.toString(max), Timestamp.offsetToString(range), max))
			
			
	def setAxisY(self, label, min, max, format):
		"Sets Y axis range (min-max) and formatting."
		if min == max:
			max += 1
		self.file.write("set yrange[%d:%d]\n" % (min, max))
		
		self.file.write("set format y \"%s\"\n" % format)
		self.file.write("set ytics out\n")
		
		self.file.write("set ylabel \"%s\"\n" % label)
	
	
	def setAxisY2(self, label, min, max, format = None):
		"Sets Y2 axis range and formatting."
		
		self.file.write("set y2range[%d:%d]\n" % (min, max))
		
		if format:
			self.file.write("set format y2 \"%s\"\n" % format)
		self.file.write("set y2tics out\n")
		self.file.write("set ytics nomirror\n")
		
		self.file.write("set y2label \"%s\"\n" % label)

	def setBMargin(self, value):
		"Sets bottom margin value. Used to reserve space for statstics at the bottom of the page."
		self.file.write("set bmargin %d\n" % value)

	def addGraph(self, file, colX, colY, title = "\"\"", axis = None, style = None, prefix = None, ):
		"Adds a graph based on datafile file  to the plot. colX, colY identifies the "
		"columns containing data X/Y data."
		if len(self.graphs):
			data = ","
		else:
			data = ""
		if prefix:
			data += prefix
		data += "\"%s\" using %s" % (file.getFilename(), colX)
		if colY:
			data += ":%s" % (colY)
		if style:
			data += " ls %d" % style
		data += " title %s" % title
		if axis:
			data += " axes %s" % axis
		data += "\\\n"
		self.graphs.append(data)
			
	def plot(self):
		"Sets the tables and plots the data files. The control/data file cleanup is performed afterwards."
		for table in self.tables:
			table.write(self.file)
			
		self.file.write("plot \\\n")
		for graph in self.graphs:
			self.file.write(graph)
		self.file.write("\n")

		Options.terminal.finish(self.file)
		
		self.file.close();
		
		# close data/configuration files
		for file in self.files:
			file.close()
		
		# Convert with gnuplot
		try:
			gnuplot = subprocess.Popen(["gnuplot", self.cfgFilename], 0, None, None, self.stream)
			gnuplot.wait()
		except OSError, e:
			print >> sys.stderr, "ERROR: failed to execute gnuplot (%s)" % e.strerror
			print >> sys.stderr, "Check if the gnuplot is installed and try again."
			self.cleanup()
			sys.exit(2)

		self.cleanup()
	
	def setLineStyle(self, type, color):
		"Creates new line style and returns its index."
		self.lineStyleIndex += 1
		self.file.write("set style line %d" % self.lineStyleIndex)
		if type:
			self.file.write(" lt %s" % type)
		if color:
			self.file.write(" linecolor rgb \"%s\"" % color)
		self.file.write("\n")
		return self.lineStyleIndex
		
	def createTable(self, row, col):
		"""
		Creates virtual table object. The tables can be used to report statistics
		or whatever table formatted information is required. A gnuplot report can
		have multiple tables.
		"""
		table = self.Table(row, col)
		self.tables.append(table)
		return table
	
	def createFile(self, filename, title = None):
		"Creates new data file. This file will be automatically removed after plotting."
		file = self.DataFile(filename, title)
		self.files.append(file)
		return file
		
	def cleanup(self):
		"Deletes configuration and data files"
		os.remove(self.cfgFilename)
		
		for file in self.files:
			file.remove();
			
	def setKey(self, key):
		"Sets the data legend position."
		self.file.write("set key %s\n" % key)
		
	def setSeparator(self, value):
		"Sets the datafile separator character"
		self.file.write("set datafile separator \"%s\"\n" % value)

	
	def setGrid(self, value):
		"Sets the grid"	
		self.file.write("set grid %s\n" % value)
	
# /class Plotter	

		
class ReportGenerator:
	"""
	The base class for all report generators.
	"""
	# the resource identifier
	_id = None
	# the plotter 
	_plotter = None

	# resource allocation overhead data
	overheadData = {"memory": 8}

	def __init__(self, id):
		self._id = id
		self.plotter = Plotter(id)
		
	def getId(self):
		return self._id

	def initialize(self):
		"Initializes generator. As options aren't fully processed during __init__, the initialize() "
		"method can be used to initialize options dependant resources."

	def processEventInContext(self, resource, context, event, allocEvent):
		""
		raise NotImplementedError()
	
	def processUnfreedEvent(self, resource, event):
		""
	
	def finish(self):
		"Finishes report"
		raise NotImplementedError()
#/class ReportGenerator		


class HistogramGenerator(ReportGenerator):
	"""
	The HistogramGenerator generates statistics about allocation count/total size per
	resource size.
	The generated report type (count or size) depends on the mode parameter passed
	in constructor.
	"""
	
	class Alloc:
		total = 0
		freed = 0
	# /class Alloc

	class Stats:
		"Stores allocation (freed/unfreed) statistics"
		count = 0
		total = 0
		allocs = None
	
		def __init__(self):
			self.allocs = []
			
		def getMedian(self):
			"Calculates median allocation size"
			nallocs = len(self.allocs)
			return nallocs and self.allocs[nallocs / 2] or 0
	# /class Stats
	
	class ResourceData:
		allocs = None
		
		def __init__(self):
			self.allocs = {}
	# /class ResourceData
	
	mode = None
	resource = None
	resourceData = None
	
	# Y axis range
	yrangeMax = 0
	
	def __init__(self, mode):
		ReportGenerator.__init__(self, "histogram-%s" % mode)
		self.mode = mode
		self.data = {}
		self.resourceData = self.ResourceData()

	def writeAlloc(self, fileData, alloc, size):
		raise NotImplementedError()
	
	def getLabelY(self):
		raise NotImplementedError()
	
	def getTitle(self):
		raise NotImplementedError()

		
	def processEventInContext(self, resource, context, event, allocEvent):
		# Histogram report does not use grouping by separate contexts
		if not context.isMaskAll():
			return
		
		# abort if the input data contains multiple resource types
		if self.resource:
			if self.resource != resource:
				print >> sys.stderr, "ERROR: multiple resources (%s,%s) detected, the results might be misleading.\n"\
				                     "Use --filter-resource options to filter a single resource." % (self.resource, resource)
				sys.exit(2)
		else:
			self.resource = resource

		# 
		resourceData = self.resourceData
		if event.type == Event.Types.ALLOC:
			# store histogram statistics
			if event.res_size not in resourceData.allocs:
				resourceData.allocs[event.res_size] = self.Alloc()
			resourceData.allocs[event.res_size].total += 1
			
		if event.type == Event.Types.FREE:
			resourceData.allocs[event.res_size].freed += 1
	
	def finish(self):
		# initialize statistics data
		statsFreed = self.Stats()
		statsUnfreed = self.Stats()
		statsSumm = self.Stats()

		resourceData = self.resourceData

		if len(resourceData.allocs) == 0:
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			plotter.cleanup()
			sys.exit(2)

		# index by size
		keys = []				
		for size in resourceData.allocs:
			keys.append(size)
		keys.sort()

		# calculate median values
		for size in keys:
			alloc = resourceData.allocs[size]
			for index in range(0, alloc.freed):
				statsFreed.allocs.append(size)
				statsSumm.allocs.append(size)
			for index in range(0, alloc.total - alloc.freed):
				statsUnfreed.allocs.append(size)
				statsSumm.allocs.append(size)

		# create data file.
		fileData = self.plotter.createFile("%s-%s.dat" % (self.getId(), self.mode))
		fileData.create()

		# create line styles for freed and unfreed bars
		self.plotter.create()
		ltUnfreed = self.plotter.setLineStyle(None, "#FF0000")
		ltFreed = self.plotter.setLineStyle(None, "#00FF00")

		# write data header 

		# Histogram data starts with second column (the first column contains
		# allocation size).
		index = 2
		fileData.writeText("size")
		self.plotter.addGraph(fileData, "%d" % index, "xtic(1)", "\"%s allocation %s (unfreed)\"" % (self.resource, self.mode), \
							None, ltUnfreed, "newhistogram \"Resource size\", ")
		self.plotter.addGraph(fileData, "%d" % (index + 1), "xtic(1)", "\"%s allocation %s (freed)\"" % (self.resource, self.mode), None, ltFreed)
		fileData.writeText("\n")

		# write data		
		for size in keys:
			fileData.writeText("%d" % size)	
			alloc = resourceData.allocs[size]
			if alloc is None:
				fileData.writeText("\t-\t-")
			else:
				unfreed = alloc.total - alloc.freed
				self.writeAlloc(fileData, alloc, size)
				
				# calculate statistics
				statsFreed.count += alloc.freed
				statsFreed.total += alloc.freed * int(size)
				
				statsUnfreed.count += unfreed
				statsUnfreed.total += unfreed * int(size)
						
			fileData.writeText("\n")

		# plot the graphs
		self.plotter.setTitle(self.getTitle())
		self.plotter.setAxisY(self.getLabelY(), 0, self.yrangeMax, "%.1s%c")
		self.plotter.setGrid("ytics")
		self.plotter.setAxisX("Resource size", None, None, None, "0")
		self.plotter.setStyle("data histogram")
		self.plotter.setStyle("histogram rowstacked")
		self.plotter.setStyle("fill solid 0.2")
		self.plotter.setSeparator("\\t")

		# write statistics table

		# define table headers
		table = self.plotter.createTable(1, 1)
		# name column
		table.addColumn(10)
		# median
		table.addColumn(12)
		# allocation count
		table.addColumn(10)
		# allocation size
		table.addColumn(12)

		table.setText(0, 0, "Allocs", "center")
		table.setText(0, 1, "Median", "center")
		table.setText(0, 2, "Count", "center")
		table.setText(0, 3, "Total Size", "center")
		
		table.setText(2, 0, "freed", "right")
		table.setText(3, 0, "unfreed", "right")
		table.setText(4, 0, "both", "right")

		table.setText(2, 1, "%d" % statsFreed.getMedian())
		table.setText(3, 1, "%d" % statsUnfreed.getMedian())
		table.setText(4, 1, "%d" % statsSumm.getMedian())
		
		table.setText(2, 2, "%d" % statsFreed.count)
		table.setText(3, 2, "%d" % statsUnfreed.count)
		table.setText(4, 2, "%d" % (statsFreed.count + statsUnfreed.count))

		table.setText(2, 3, "%d" % statsFreed.total)
		table.setText(3, 3, "%d" % statsUnfreed.total)
		table.setText(4, 3, "%d" % (statsFreed.total + statsUnfreed.total))
		
		self.plotter.setBMargin(10)
		self.plotter.setKey("invert")
		
		self.plotter.plot()

	
# /class HistogramGenerator

class SizeHistogramGenerator(HistogramGenerator):

	def __init__(self):
		HistogramGenerator.__init__(self, "size")
		
	def writeAlloc(self, fileData, alloc, size):
		unfreed = alloc.total - alloc.freed
		fileData.writeText("\t%d\t%d" % ((int(size) * unfreed), int(size) * alloc.freed))
		if self.yrangeMax < alloc.total * int(size):
			self.yrangeMax = alloc.total * int(size)
			
	def getLabelY(self):
		return "Total allocation size"
	
	def getTitle(self):
		return "Total allocation size per resource size"

# /class SizeHistogramGenerator


class CountHistogramGenerator(HistogramGenerator):

	def __init__(self):
		HistogramGenerator.__init__(self, "count")
		
	def writeAlloc(self, fileData, alloc, size):
		unfreed = alloc.total - alloc.freed
		fileData.writeText("\t%d\t%d" % (unfreed, alloc.freed))
		if self.yrangeMax < alloc.total:
			self.yrangeMax = alloc.total
			
	def getLabelY(self):
		return "Allocation count"
	
	def getTitle(self):
		return "Allocation count per resource size"
			

# /class CountHistogramGenerator


class LifetimeGenerator(ReportGenerator):
	"""
	The LifetimeGenerator class generates resource life time
	report. This report contains lines displaying resource
	allocation and release times.
	"""

	class Stats:
		"""
		Resource lifetime statistics.
		"""
		class Data:
			"""
			Resource lifetime statistics data.
			"""
			# allocation sie
			size = 0
			# number of allocations of this size
			count = 0
			# time of the first allocation of this size
			timestamp = 0
			
			def __init__(self):
				pass
		# /class Data
		
		# the minimal allocation size statistics
		min = None
		# the maximal allocation size statistics
		max = None
		
		def __init__(self):
			self.min = self.Data()
			self.max = self.Data()
			self.min.size = sys.maxint
	# /class Stats
	
	
	class ContextData:
		"Context data container"
		fileLifetime = None
		total = 0
		allocs = None
		
		def __init__(self, file):
			self.fileLifetime = file
			self.allocs = []
	
	class ResourceData:
		"Resource data container"
		stats = None
		eventFiles = None
		contextFiles = None
		total = 0
		allocs = None
				
		def __init__(self):
			self.stats = LifetimeGenerator.Stats()
			self.eventFiles = []
			self.contextFiles= {}
			self.allocs = []
			
	#/class ResourceData

	# axis range
	xrangeMin = None
	xrangeMax = 0
	yrangeMin = 0
	yrangeMax = 0
	
	#
	totalLifelines = 0
	DETAILS_LIMIT = 20
	
	def __init__(self):
		ReportGenerator.__init__(self, "lifetime")
		self.stats = {}
		self.data = {}

		self.stats = {}
		self.data = {}


	def registerAlloc(self, resource, event, endTimestamp):
		resourceData = self.data[resource]
		contextFile = resourceData.contextFiles[event.context]

		contextFile.write(event.timestamp, event.res_size)
		contextFile.write(endTimestamp, event.res_size)
		contextFile.writeSeparator()
		
		if self.totalLifelines < self.DETAILS_LIMIT:
			file = self.plotter.createFile("%s-%s-%d.dat" % (self.getId(), resource, event.index), "%s (%x)" % (resource, event.res_id))
			file.write(event.timestamp, event.res_size)
			file.write(endTimestamp, event.res_size)
			file.writeSeparator()
			resourceData.eventFiles.append(file)
		
		self.totalLifelines += 1
		

	def processEventInContext(self, resource, context, event, allocEvent):
		# lifetime report does not use grouping by separate contexts
		if not context.isMaskAll():
			return
		
		# create data containers if necessary
		if resource not in self.data:
			self.data[resource] = self.ResourceData()
		resourceData = self.data[resource]
			
		if event.context not in resourceData.contextFiles:
			contextName = ""
			if event.context != 0:
				contextName = " (@%x)" % event.context
			resourceData.contextFiles[event.context] = self.plotter.createFile("%s-contextd-%s-%x.dat" % 
					(self.getId(), resource, context.value), "%s%s" % (resource, contextName))
			
		contextFile = resourceData.contextFiles[event.context]
		stats = resourceData.stats
		
		# update X axis range
		if self.xrangeMin is None:
			self.xrangeMin = event.timestamp
		if self.xrangeMax < event.timestamp:
			self.xrangeMax = event.timestamp
			
		if event.type == Event.Types.ALLOC:
			# index the event by resource id.
			resourceData.allocs.append(event.res_size)
			resourceData.total += event.res_size

			# update Y axis range value
			size = event.res_size
			if size > self.yrangeMax:
				self.yrangeMax = size
				
			# gather statistics
			if event.res_size < stats.min.size:
				stats.min.size = event.res_size
				stats.min.count = 0
				stats.min.timestamp = event.timestamp
			if event.res_size == stats.min.size:
				stats.min.count += 1
			if event.res_size > stats.max.size:
				stats.max.size = event.res_size
				stats.max.count = 0
				stats.max.timestamp = event.timestamp
			if event.res_size == stats.max.size:
				stats.max.count += 1
					
		if event.type == Event.Types.FREE:
			self.registerAlloc(resource, allocEvent, event.timestamp)
			
	def processUnfreedEvent(self, resource, event):
		self.registerAlloc(resource, event, self.xrangeMax)

			
	def finish(self):
		# Check if the gathered data is not empty
		if self.yrangeMax == 0:
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			self.plotter.cleanup()
			sys.exit(0)
		
		# Adjust X axis range to contain at least single point
		if self.xrangeMax == self.xrangeMin:
			self.xrangeMax += 1
		
		
		ngraphs = 0
			
		for resource, resourceData in self.data.iteritems():
			# add the graphs to the plot
			if self.totalLifelines < self.DETAILS_LIMIT:
				for file in resourceData.eventFiles:
					self.plotter.addGraph(file, "1", "2", "column(2)")
					ngraphs += 1
			else:
				for file in resourceData.contextFiles.itervalues():
					self.plotter.addGraph(file, "1", "2", "column(2)")
					ngraphs += 1
				
			# draw statistics markers
			resourceData.allocs.sort()
			alloc_count = len(resourceData.allocs)
			statAverage = resourceData.total / alloc_count;
			statMedian = resourceData.allocs[alloc_count / 2 - 1]
			if alloc_count % 2 == 0:
				statMedian = (statMedian + resourceData.allocs[alloc_count / 2]) / 2
		
			file = self.plotter.createFile("%s-%s-average" % (self.getId(), resource), "%s (average:%d)" % (resource, statAverage))
			self.plotter.addGraph(file, "1", "2", "column(2)")
			file.write(self.xrangeMin, statAverage)
			file.write(self.xrangeMax, statAverage)

			file = self.plotter.createFile("%s-%s-median" % (self.getId(), resource), "%s (median:%d)" % (resource, statMedian))
			self.plotter.addGraph(file, "1", "2", "column(2)")
			file.write(self.xrangeMin, statMedian)
			file.write(self.xrangeMax, statMedian)

		# increase Y  range, so the top graph isn't hidden beyond the axis	
		self.yrangeMax = self.yrangeMax * 105 / 100	
		
		# plot the graphs
		self.plotter.create()
		self.plotter.setTitle("Resource life-time")
		self.plotter.setAxisX("time (secs)", self.xrangeMin, self.xrangeMax)
		self.plotter.setAxisY("size", self.yrangeMin, self.yrangeMax, "%.1s%c")
		
		if self.totalLifelines > self.DETAILS_LIMIT:
			self.plotter.setStyle("data lines")
		else:
			self.plotter.setStyle("data linespoints")
			
		# define table headers
		table = self.plotter.createTable(1, 1)
		# resource name column
		table.addColumn(10)
		# snapshot name
		table.addColumn(5)
		# allocation count
		table.addColumn(8)
		# allocation size
		table.addColumn(10)
		# timestamp
		table.addColumn(12)

		table.setText(0, 0, "Resource", "center")
		table.setText(0, 1, "State", "center")

		table.setText(0, 2, "Size", "center")
		table.setText(0, 3, "Count", "center")
		table.setText(0, 4, "Time", "center")

		# write statistics data
		resourceIndex = 2
		for resource in self.data:
			stats = self.data[resource].stats
			table.setText(resourceIndex, 0, resource, "left")
			table.setText(resourceIndex, 1, "min", "center")
			table.setText(resourceIndex, 2, "%d" % stats.min.size)
			table.setText(resourceIndex, 3, "%d" % stats.min.count)
			table.setText(resourceIndex, 4, "%s" % Timestamp.toString(stats.min.timestamp))

			resourceIndex += 1
			table.setText(resourceIndex, 1, "max", "center")
			table.setText(resourceIndex, 2, "%d" % stats.max.size)
			table.setText(resourceIndex, 3, "%d" % stats.max.count)
			table.setText(resourceIndex, 4, "%s" % Timestamp.toString(stats.max.timestamp))
			
			resourceIndex += 2
		
		# Reserve space at the bottom for statistics data
		bmargin = ngraphs + 9
		if bmargin < 9 + table.rows:
			bmargin = 9 + table.rows
		if bmargin < 15:
			bmargin = 15
			
		# if the legend contains too many graphs - write it at the left side instead of the bottom.
		if self.totalLifelines < self.DETAILS_LIMIT and bmargin < self.totalLifelines + 5:
			self.plotter.setKey("right outside")
			
		self.plotter.setBMargin(bmargin)

		self.plotter.plot()
	
# /class LifetimeGenerator


class ActivityGenerator(ReportGenerator):
	"""
	The ActivityGenerator class generates 'activity' report.
	The activity report contains graphs displaying the resource allocation rate per time slice.
	The allocation rate is calculated by going through events by time based steps and calculating
	the allocation rate for each step by dividing the total allocation size with total allocation
	number for all allocations during the last time slice period. 
	Usually the step value is set to half of the specified time slice.
	"""

	class Stats:
		"""
		Resource allocation activity statistics 
		"""
		class Data:
			count = 0
			size = 0
			timestamp = 0
			file = None
		# /class Data

		peakSize = None
		peakAllocs = None
		peakFrees = None
		
		def __init__(self):
			self.peakSize = self.Data()
			self.peakAllocs = self.Data()
			self.peakFrees = self.Data()

		def update(self, contextData, timestamp):
			if contextData.total > self.peakSize.size:
				self.peakSize.size = contextData.total
				self.peakSize.count = contextData.allocs
				self.peakSize.timestamp = timestamp
			if contextData.allocs > self.peakAllocs.count:
				self.peakAllocs.size = contextData.total
				self.peakAllocs.count = contextData.allocs
				self.peakAllocs.timestamp = timestamp
			if contextData.frees > self.peakFrees.count:
				self.peakFrees.count = contextData.frees
				self.peakFrees.size = contextData.total
				self.peakFrees.timestamp = timestamp
			
	# /class Stats

	class ContextData:
		"Data files used for single resource-context graph"
		fileRate = None
		fileAllocs = None
		fileFrees = None
		
		# statistics data
		total = 0
		allocs = 0
		frees = 0
		
		# slice data
		sliceEvents = None
		
		def __init__(self, fileRate, fileAllocs, fileFrees):
			self.fileRate = fileRate
			self.fileAllocs = fileAllocs
			self.fileFrees = fileFrees
			
			self.sliceEvents = []
	
		def processSlice(self, timestamp, slice, stats):
			# remove old events
			while len(self.sliceEvents) > 0 and self.sliceEvents[0].timestamp < timestamp - slice:
				oldEvent = self.sliceEvents.pop(0)
				if oldEvent.type == Event.Types.ALLOC:
					self.total -= oldEvent.res_size
					self.allocs -= 1
				if oldEvent.type == Event.Types.FREE:
					self.frees -= 1
			
			# write graphs
			self.fileRate.write(timestamp, self.total)
			self.fileAllocs.write(timestamp, self.allocs)
			self.fileFrees.write(timestamp, self.frees)

		def addEvent(self, event):
			if event.type == Event.Types.ALLOC:
				self.total += event.res_size
				self.allocs += 1
			if event.type == Event.Types.FREE:
				self.frees +=1
			self.sliceEvents.append(event)

			
	# /class ContextData

	class ResourceData:
		stats = None
		contexts = None
		
		def __init__(self):
			self.stats = ActivityGenerator.Stats();
			self.contexts = {}
		
	# /class ResourceData

	# the time slice (20 seconds by default) 
	slice = None
	step = 0
	
	# axis range
	yrangeMin = 0
	yrangeMax = 0
	y2rangeMin = 0
	y2rangeMax = 0
	xrangeMin = None
	xrangeMax = 0

	# data files
	data = None
	
	# the current time slice value
	sliceTimestamp = None
	
		
	def __init__(self):
		ReportGenerator.__init__(self, "activity")
		self.data = {}


	def initialize(self):
		#
		self.slice = Tic(Options.slice or 200, False)
		# calculate step value for statistics checkpoints
		self.step = self.slice.value / 2
		if self.step < 1:
			self.step = 1

	def updateRangeY(self, contextData):
		# update Y, Y2 axis ranges
		if contextData.total > self.yrangeMax:
			self.yrangeMax = contextData.total
		if contextData.allocs > self.y2rangeMax:
			self.y2rangeMax = contextData.allocs
		if contextData.frees > self.y2rangeMax:
			self.y2rangeMax = contextData.frees
			
	def updateRangeX(self, timestamp):
		if self.xrangeMin is None:
			self.xrangeMin = timestamp
		if timestamp > self.xrangeMax:
			self.xrangeMax = timestamp
	
	def processEventInContext(self, resource, context, event, allocData):
		# update X axis range
		self.updateRangeX(event.timestamp)
		
		# create data containers if necessary
		if resource not in self.data:
			self.data[resource] = self.ResourceData()
		resourceData = self.data[resource]
			
		if context.value not in resourceData.contexts:
			fileRate = self.plotter.createFile("%s-%s-size-%x.dat" % (self.getId(), resource, context.value), \
												"%s (rate:%s)" % (resource, context.name))
			fileRate.write(self.xrangeMin, 0)
			fileAllocs = self.plotter.createFile("%s-%s-allocs-%x.dat" % (self.getId(), resource, context.value),\
												"%s (allocs:%s)" % (resource, context.name))
			fileAllocs.write(self.xrangeMin, 0)
			fileFrees = self.plotter.createFile("%s-%s-frees-%x.dat" % (self.getId(), resource, context.value),\
											 	"%s (frees:%s)" % (resource, context.name))
			fileFrees.write(self.xrangeMin, 0)
			
			resourceData.contexts[context.value] = self.ContextData(fileRate, fileAllocs, fileFrees)

		contextData = resourceData.contexts[context.value]
		stats = resourceData.stats

			
		if self.sliceTimestamp is None:
			self.sliceTimestamp = event.timestamp
	
		timestamp = self.sliceTimestamp + self.step
		
		# process timeslice if the event timestamp is beyond it
		if timestamp <= event.timestamp:
			contextData.processSlice(timestamp, self.slice.value, stats)
		
			# store peak values
			if context.isMaskAll():
				stats.update(contextData, timestamp)

			# update Y axis range	
			self.updateRangeY(contextData)
			
			# update slice timestamp
			self.sliceTimestamp = timestamp

		# add event to the timeslice
		contextData.addEvent(event)		
			
	
	def finish(self):
		""
		
		# number of graphs (without counting overhead data)
		ngraphs = 0

		# find the the timestamp for the last slice
		timestamp = self.sliceTimestamp + self.step
		self.updateRangeX(timestamp)

		# calculate last slice data
		for resource in self.data:
			resourceData = self.data[resource]
			stats = resourceData.stats
			for context in resourceData.contexts:
				contextData = resourceData.contexts[context]
				contextData.processSlice(timestamp, self.slice.value, stats)
				
		# update Y axis range	
		self.updateRangeY(contextData)

		# Check if the gathered data is not empty
		if self.yrangeMax == 0:		
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			self.plotter.cleanup()
			sys.exit(0)
	
		# increase Y range, so top graph isn't hidden beyond the axis	
		self.yrangeMax = self.yrangeMax * 105 / 100

		for resource in self.data:
			resourceData = self.data[resource]
			stats = resourceData.stats
			for context in resourceData.contexts:
				# store peak values
				if context == 0xFFFFFFFF:
					stats.update(contextData, timestamp)
				
				self.plotter.addGraph(contextData.fileRate, "1", "2", "column(2)")
				self.plotter.addGraph(contextData.fileAllocs, "1", "2", "column(2)", "x1y2")
				self.plotter.addGraph(contextData.fileFrees, "1", "2", "column(2)", "x1y2")
				ngraphs += 3

			# plot the peak markers
			file = self.plotter.createFile("%s-%s-size-peak.dat" % (self.getId(), resource), \
										"%s (peak rate:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakSize.timestamp, self.yrangeMin)
			file.write(stats.peakSize.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")
	
			file = self.plotter.createFile("%s-%s-allocs-peak.dat" % (self.getId(), resource), \
										"%s (peak allocs:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakAllocs.timestamp, self.yrangeMin)
			file.write(stats.peakAllocs.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")

			file = self.plotter.createFile("%s-%s-frees-peak.dat" % (self.getId(), resource),
										"%s (peak frees:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakFrees.timestamp, self.yrangeMin)
			file.write(stats.peakFrees.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")

		#	
		# generate gnuplot configuration file:
		#
		self.plotter.create()
		self.plotter.setTitle("Allocation/deallocation rate")
		
		self.plotter.setAxisX("time (secs)", self.xrangeMin, self.xrangeMax)
		self.plotter.setAxisY("amount per %s sec" % self.slice.getText(), self.yrangeMin, self.yrangeMax, "%.1s%c")
		self.plotter.setAxisY2("count per %s sec" % self.slice.getText(), self.y2rangeMin, self.y2rangeMax)
			
		self.plotter.setStyle("data lines")
		
		# Write summary report
		
		# define table headers
		table = self.plotter.createTable(1, 1)
		# resource name column
		table.addColumn(10)
		# snapshot name column
		table.addColumn(10)
		# allocation count
		table.addColumn(8)
		# allocation size
		table.addColumn(10)

		table.setText(0, 0, "Resource", "center")
		table.setText(0, 1, "State", "center")

		table.setText(0, 2, "Count", "center")
		table.setText(0, 3, "Size", "center")

		# write summary data
		resourceIndex = 2
		for resource in self.data:
			stats = self.data[resource].stats
			table.setText(resourceIndex, 0, resource, "left")
			table.setText(resourceIndex, 1, "peak size", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakSize.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakSize.size)

			resourceIndex += 1
			table.setText(resourceIndex, 1, "peak allocs", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakAllocs.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakAllocs.size)
			
			resourceIndex += 1
			table.setText(resourceIndex, 1, "peak frees", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakFrees.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakFrees.size)
			
			resourceIndex += 2
		
		# Reserve space at the bottom for leak data
		bmargin = ngraphs + 9
		if bmargin < 9 + table.rows:
			bmargin = 9 + table.rows
		if bmargin < 15:
			bmargin = 15
		self.plotter.setBMargin(bmargin)
		
		# plot the data files
		self.plotter.plot()

		

# /class ActivityGenerator


class TotalsGenerator(ReportGenerator):
	"""
	The TotalsGenerator class generates 'totals' report.
	The 'totals' report contains graph displaying the total resource allocation over the time.
	"""
	class Stats:
		"""
		Resource allocation statistics 
		"""
		class Data:
			count = 0
			size = 0
		# /class Data
		
		# 'leaked' allocations at the end of report
		endLeaks = None
		# 'leaked' allocations at the peak time
		peakLeaks = None
		# total allocations at the end of report
		endTotals = None
		# total allocations at the peak time
		peakTotals = None
		# peak allocation timestamp
		peakTimestamp = 0

		def __init__(self):
			# non-freed allocations at the end of trace
			self.endLeaks = self.Data()
			# non-freed allocations at the peak time
			self.peakLeaks = self.Data()
			# total allocations at the end of trace
			self.endTotals = self.Data()
			# total allocations at the peak time
			self.peakTotals = self.Data()
	# /class Stats
	

	class ContextData:
		fileTotals = None
		total = 0
		
		def __init__(self, fileTotals):
			self.fileTotals = fileTotals
	# /class ContextData
	
	class ResourceData:
		"Data files used for single resource-context graph"
		
		overhead = 0
		fileOverhead = None

		contexts = None
				
		def __init__(self, fileOverhead):
			self.fileOverhead = fileOverhead
			self.contexts = {}
			self.stats = TotalsGenerator.Stats()
	# /class ResourceData


	# Axis range
	xrangeMin = None
	xrangeMax = 0
	yrangeMin = 0
	yrangeMax = 0
	
	#
	data = None
	
	
	def __init__(self):
		ReportGenerator.__init__(self, "totals")
		self.data = {}
		
	def processEventInContext(self, resource, context, event, allocData):
		if resource not in self.data:
			if resource in self.overheadData:
				fileOverhead = self.plotter.createFile("%s-%s-overhead.dat" % (self.getId(), resource), "%s overhead" % resource)
			else:
				fileOverhead = None
			self.data[resource] = self.ResourceData(fileOverhead)
		resourceData = self.data[resource]
			
		if context.value not in resourceData.contexts:
			fileTotals = self.plotter.createFile("%s-%s-%x.dat" % (self.getId(), resource, context.value), \
																		"%s (%s)" % (resource, context.name))
			resourceData.contexts[context.value] = self.ContextData(fileTotals)

		contextData = resourceData.contexts[context.value]
		stats = resourceData.stats
		
		# update X axis range
		if self.xrangeMin is None:
			self.xrangeMin = event.timestamp
		if self.xrangeMax  < event.timestamp:
			self.xrangeMax = event.timestamp
						
		if event.type == Event.Types.ALLOC:
			contextData.total += event.res_size
			# update statistics only when events aren't filtered by contexts
			if context.isMaskAll():
				stats.endLeaks.size += event.res_size
				stats.endLeaks.count += 1
				stats.endTotals.size += event.res_size
				stats.endTotals.count += 1
				if stats.endLeaks.size > stats.peakLeaks.size:
					stats.peakLeaks.size = stats.endLeaks.size
					stats.peakLeaks.count = stats.endLeaks.count
					stats.peakTotals.size = stats.endTotals.size
					stats.peakTotals.count = stats.endTotals.count
					stats.peakTimestamp = event.timestamp
				# update overhead data
				if resource in self.overheadData:
					resourceData.overhead += event.res_size + self.overheadData[resource]
							
		if event.type == Event.Types.FREE:
			contextData.total -= event.res_size
			# update statistics only when events aren't filtered by contexts
			if context.isMaskAll():
				stats.endLeaks.size -= event.res_size
				stats.endLeaks.count -= 1
				# update overhead data
				if resource in self.overheadData:
					resourceData.overhead -= (event.res_size + self.overheadData[resource])
			
		contextData.fileTotals.write(event.timestamp, contextData.total)

		if context.isMaskAll() and self.data[resource].fileOverhead:
			self.data[resource].fileOverhead.write(event.timestamp, resourceData.overhead)

		# update the Y axis range
		if contextData.total > self.yrangeMax:
			self.yrangeMax = contextData.total
		if resourceData.overhead > self.yrangeMax:
			self.yrangeMax = resourceData.overhead


	def finish(self):
		# Check if the gathered data is not empty
		if self.yrangeMax == 0:		
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			self.plotter.cleanup()
			sys.exit(0)
	
		# increase Y range, so top graph isn't hidden beyond the axis	
		self.yrangeMax = self.yrangeMax * 105 / 100
		
		# number of graphs (without counting overhead data)
		ngraphs = 0

		# add the collected data to the graph
		for resource in self.data:
			resourceData = self.data[resource]
			for context in resourceData.contexts:
				self.plotter.addGraph(resourceData.contexts[context].fileTotals, "1", "2", "column(2)")
				ngraphs += 1

			if self.data[resource].fileOverhead:
				self.plotter.addGraph(resourceData.fileOverhead, "1", "2", "column(2)")

			timestamp = resourceData.stats.peakTimestamp
			file = self.plotter.createFile("%s-%s-peak.dat" % (self.getId(), resource), "%s (peak:%s)\n" % (resource, Timestamp.toString(timestamp)))
			file.write(timestamp, self.yrangeMin)
			file.write(timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")
			
		#	
		# generate gnuplot configuration file:
		#
		self.plotter.create()
		self.plotter.setTitle("Amount of non-freed allocations")
		
		self.plotter.setAxisX("time (secs)", self.xrangeMin, self.xrangeMax)
		self.plotter.setAxisY("size", self.yrangeMin, self.yrangeMax, "%.1s%c")
			
		self.plotter.setStyle("data lines")
		
		# Write summary report
		
		# define table headers
		table = self.plotter.createTable(1, 1)
		# resource name column
		table.addColumn(10)
		# snapshot name column
		table.addColumn(5)
		# total allocation count
		table.addColumn(8)
		# total allocation size
		table.addColumn(10)
		# leaked allocation count
		table.addColumn(8)
		# leaked allocation size
		table.addColumn(10)

		table.setText(1, 0, "Resource", "center")
		table.setText(1, 1, "State", "center")

		table.setText(0, 2, "Total", "center")
		table.setText(0, 3, "Total", "center")
		table.setText(1, 2, "count", "center")
		table.setText(1, 3, "size", "center")

		table.setText(0, 4, "Non-freed", "center")
		table.setText(0, 5, "Non-freed", "center")
		table.setText(1, 4, "count", "center")
		table.setText(1, 5, "size", "center")
		
		# write summary data
		resourceIndex = 3
		for resource in self.data:
			stats = self.data[resource].stats
			table.setText(resourceIndex, 0, resource, "left")
			table.setText(resourceIndex, 1, "peak", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakTotals.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakTotals.size)
			table.setText(resourceIndex, 4, "%d" % stats.peakLeaks.count)
			table.setText(resourceIndex, 5, "%d" % stats.peakLeaks.size)

			resourceIndex += 1
			table.setText(resourceIndex, 1, "end", "center")
			table.setText(resourceIndex, 2, "%d" % stats.endTotals.count)
			table.setText(resourceIndex, 3, "%d" % stats.endTotals.size)
			table.setText(resourceIndex, 4, "%d" % stats.endLeaks.count)
			table.setText(resourceIndex, 5, "%d" % stats.endLeaks.size)
			
			resourceIndex += 2
		
		# Reserve space at the bottom for leak data
		bmargin = ngraphs + 9
		if bmargin < 9 + table.rows:
			bmargin = 9 + table.rows
		if bmargin < 15:
			bmargin = 15
		self.plotter.setBMargin(bmargin)
		# plot the data files
		self.plotter.plot()

# /class TotalsGenerator		
				
				
		
class Processor:
	"""
	This class processes the resource, context, events registering methods 
	and calls report generator hooks.
	"""
	
	class Index:
		"""
		This class is used to index resources by their identifiers. It's 
		used to minimize event lookups by resource identifier times.
		"""
		event = None
		refCount = 0
		resource = None
		
		def __init__(self, resource, event):
			self.resource = resource
			self.event = event
			self.refCount = 1
	# /class Index
	
	# context list
	contexts = None
	
	# resource list
	resources = None

	# report generators
	generators = None
	
	# event index used to track resource reference counting mechanism
	eventIndex = None
	
	# last timestamp/index to check event order
	lastIndex = 0
	lastTimestamp = 0
	
	def __init__(self):
		self.contexts = [Context(Context.MASK_ALL, "all allocations")]
		self.resources = {}
		self.generators = []
		self.eventIndex = {}
		
	def addGenerator(self, generator):
		"Adds a report generator"
		self.generators.append(generator)

	def isEventInRange(self, event):
		"Checks if the event matches the filters specified in Options."
		for filter in Options.filters:
			if not filter.matchesEvent(event):
				return False
		return True
	
	def processUnfreedEvents(self):
		for ievent in self.eventIndex.itervalues():
			for generator in self.generators:
				generator.processUnfreedEvent(ievent.resource.type, ievent.event)

	
	def processEvent(self, resource, event, allocEvent = None):
		"Processes the event in report generators"
		# check if events are properly ordered
		if self.lastTimestamp > event.timestamp or (self.lastTimestamp == event.timestamp and self.lastIndex > event.index):
			print >> sys.stderr, "ERROR: older event follows newer one in source file at index %d.\n" % event.index
			print >> sys.stderr, "To force a correct event ordering in the source file, run:\n\tsp-rtrace-postproc -i <source file> | rtrace-timeline <options>"
			sys.exit(2)

		self.lastTimestamp = event.timestamp
		self.lastIndex = event.index
				
		# call processXX calls for every context in all generators
		for context in self.contexts:
			if not event.matchContext(context):
				continue
			for generator in self.generators:
				generator.processEventInContext(resource.type, context, event, allocEvent)
	
	def registerAlloc(self, index, context, timestamp, res_type, res_id, res_size):
		"Registers resource allocation"
		if res_type is None:
			res_type = self.resources.keys()[0]
		else:
			if Options.filterResource and Options.filterResource != res_type:
				return
		if res_type not in self.resources:
			print >> sys.stderr, "Unknown resource type: %s" % res_type
			sys.exit(2)
		resource = self.resources[res_type]
		
		# process reference counting if necessary
		if resource.refCounted:
			if res_id in self.eventIndex:
				self.eventIndex[res_id].refCount += 1
				return
				
		# create a new event
		event = Event(Event.Types.ALLOC, index, context, timestamp, res_id, res_size)

		# check if the event matches the specified filters
		if not self.isEventInRange(event):
			return
		
		# register the allocation
		self.eventIndex[res_id] = self.Index(resource, event);
		
		self.processEvent(resource, event)

		
	def registerFree(self, index, context, timestamp, res_type, res_id):
		"Registers resource deallocation"
		if res_type is None:
			res_type = self.resources.keys()[0]
		else:
			if Options.filterResource and Options.filterResource != res_type:
				return
		if res_type not in self.resources:
			print >> sys.stderr, "Unknown resource type: %s" % res_type
			sys.exit(2)
		resource = self.resources[res_type]

		# process only the deallocation events for resources allocated in the scope
		if res_id not in self.eventIndex:
			return

		ievent = self.eventIndex[res_id]

		# process reference counting if necessary
		if resource.refCounted:
			ievent.refCount -= 1
			if ievent.refCount > 0:
				return

		# create a new event
		event = Event(Event.Types.FREE, index, context, timestamp, res_id, ievent.event.res_size)

		# check if the event matches the specified filters
		if not self.isEventInRange(event):
			return

		# undergister the allocation
		del self.eventIndex[res_id]

		self.processEvent(resource, event, ievent.event)

		
	def registerContext(self, value, name):
		"Registers context declaration"
		if len(self.contexts == 1):
			contexts.append(Context(Context.MASK_NONE, "no contexts"))
		self.contexts.append(Context(value, name))
		
	def registerResource(self, resource, refCounted = True):
		"Registers tracked resource"
		if Options.filterResource is None or Options.filterResource == resource:
			self.resources[resource] = Resource(resource, refCounted)
			
	def finishReports(self):
		"Finishes the reports"
		for generator in self.generators:
			generator.finish()
	
	def initialize(self):
		"Initailizes generators"
		for generator in self.generators:
			generator.initialize()
	
#/class Processor	
	
class Parser:
	"""
	This class parses the sp-rtrace format log file and calls the assigned processor
	to produce the required report file.
	"""
	processor = None
	reAlloc = re.compile("^([0-9]+)\.(?: @([0-9a-fA-F]+)|) [^[]*\[([^\]]+)\][^(<]+(?:<([^>]+)>|)\(([^)]+)\) = (0x[a-fA-F0-9]+)(.*)$")
	reFree = re.compile("^([0-9]+)\.(?: @([0-9a-fA-F]+)|) [^[]*\[([^\]]+)\][^(<]+(?:<([^>]+)>|)\((0x[a-fA-F0-9]+)\)$")
	reResource = re.compile("\<([0-9a-z]+)\> : ([^ ]+) \(([^\)]+)\)")
	reContext = re.compile("^\@ ([0-9a-fA-F]+) : (.*)$")
	
	# event list
	events = None
	# context list
	contexts = None
	# event processor
	processor = None
	
	def __init__(self, processor):
		self.events = {}
		self.contexts = []
		self.processor = processor
		
	def read(self, stream):
		"Reads and parses the input stream"
		for line in stream:
			# don't attempt to parse backtrace records
			if line[0] == '\t' or line[0] == '\n':
				continue
			#
			match = self.reAlloc.match(line)
			if match:
				context = match.group(2)
				if context is None:
					context = 0
				self.processor.registerAlloc(int(match.group(1)), context, Timestamp.fromString(match.group(3)), match.group(4), \
											int(match.group(6), 16), int(match.group(5)))
				continue
			match = self.reFree.match(line)
			if match:
				context = match.group(2)
				if context is None:
					context = 0
				self.processor.registerFree(int(match.group(1)), context, Timestamp.fromString(match.group(3)), match.group(4), \
										int(match.group(5), 16) )
				continue
			match = self.reResource.match(line)
			if match:
				self.processor.registerResource(match.group(2))
				continue
			match = self.reContext.match(line)
			if match:
				self.processor.registerContext(int(match.group(1), 16), match.group(2))
				continue
			
		self.processor.processUnfreedEvents()
			
		# sort the events by timestamp/index
#		for resource in self.events.keys():
#			self.events[resource] = sorted(self.events[resource], key = operator.attrgetter("index"))
#			self.events[resource] = sorted(self.events[resource], key = operator.attrgetter("timestamp"))
			
		
# /class Parser	
	

class Options:
	"""
	This class contains options parser implementation.
	"""

	class Fonts:
		NORMAL = "LiberationSans"
		ITALIC = "LiberationSans-Italic"
		BOLDITALIC = "LiberationSans-BoldItalic"
	# /class Fonts

	GDFONTPATH = "/usr/share/fonts/truetype/ttf-liberation"

		
	streamIn = sys.stdin
	# output filename
	outFilename = None
	# the output file extension
	outExtension = None
	# time slice value for activity report
	slice = None
	
	# true when png output is requested
	isPng = False
	
	#
	fonts = Fonts()
	
	# filter list
	filters = []
	# filter list textual interpretation
	filterString = None
	# the resource to filter
	filterResource = None
	
	# the output scaling factor
	scaleX = 1
	scaleY = 1
	
	def parse(argv):
		"Parses the command line arguments and initializes options."
		try:
			opts, args = getopt.gnu_getopt(argv, "tlahsco:i:S:ew", 
										["totals", 
										 "lifetime",
										 "activity", 
										 "in=",
										 "out=",
										 "slice=",
										 "eps",
										 "wxt",
										 "histogram-count",
										 "histogram-size",
										 "scale=",
										 "scalex=",
										 "scaley=",
										 "filter-size=",
										 "filter-time=",
										 "filter-index=",
										 "filter-context=",
										 "filter-resource=",
										 "help"])
		except getopt.GetoptError, err:
			print >> sys.stderr, str(err) 
			Options.displayUsage()
			sys.exit(2)
		
		processor = Processor()
		parser = Parser(processor)
		terminal = None
		
		for opt, val in opts:
			if opt == "-t" or opt == "--totals":
				processor.addGenerator(TotalsGenerator())
				continue
				
			if opt == "-l" or opt == "--lifetime":
				processor.addGenerator(LifetimeGenerator())
				continue
				
			if opt == "-a" or opt == "--activity":
				processor.addGenerator(ActivityGenerator())
				continue

			if opt == "-c" or opt == "--histogram-count":
				processor.addGenerator(CountHistogramGenerator())
				continue

			if opt == "-s" or opt == "--histogram-size":
				processor.addGenerator(SizeHistogramGenerator())
				continue
				
			if opt == "-i" or opt == "--in":
				Options.streamIn = open(val, "r")
				continue
				
			if opt == "-o" or opt == "--out":
				Options.outFilename = val
				continue
			
			if opt == "-S" or opt == "--slice":
				Options.slice = int(val)
				continue
				
			if opt == "-e" or opt == "--eps":
				terminal = EpsTerminal()
				Options.outExtension = ".eps"
				continue
			
			if opt == "-w" or opt == "--wxt":
				terminal = WxtTerminal()
				continue
				
			if opt == "--scale":
				Options.scaleX = float(val)
				Options.scaleY = float(val)
				continue

			if opt == "--scalex":
				Options.scaleX = float(val)
				continue

			if opt == "--scaley":
				Options.scaleY = float(val)
				continue
				
			if opt == "--filter-size":
				match = re.match("([0-9kmKM]*)-([0-9kmKM]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid size filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("size", val)
				min = Options.parseSize(match.group(1))
				max = Options.parseSize(match.group(2))
				if min:
					Options.filters.append(MinSizeFilter(min))
				if max:
					Options.filters.append(MaxSizeFilter(max))
				continue
				
			if opt == "--filter-time":
				match = re.match("([0-9:.+]*)-([0-9:.+]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid timestamp filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("time", val)
				start = Options.parseTime(match.group(1))
				end = Options.parseTime(match.group(2))
				if start:
					Options.filters.append(start > 0 and MinTimeFilter(start) or MinTimeOffsetFilter(-start))
				if end:
					Options.filters.append(end > 0 and MaxTimeFilter(end) or MaxTimeOffsetFilter(-end))
				continue
				
			if opt == "--filter-index":
				match = re.match("([0-9]*)-([0-9]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid size filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("index", val)
				min = Options.parseSize(match.group(1))
				max = Options.parseSize(match.group(2))
				if min:
					Options.filters.append(MinIndexFilter(min))
				if max:
					Options.filters.append(MaxIndexFilter(max))
				continue
			
			if opt == "--filter-context":
				Options.updateFilter("context", val)
				Options.filters.append(ContextFilter(int(val, 16)))
				continue
				
			if opt == "--filter-resource":
				Options.updateFilter("resource", val)
				Options.filterResource = val
				continue 
			
			if opt == "-h" or opt == "--help":
				Options.displayUsage()
				sys.exit(0)
				
		if len(processor.generators) < 1:
			print >> sys.stderr, "No report type specified."
			Options.displayUsage()
			sys.exit(2)
		
		# set the output terminal	
		if terminal is None:
			terminal = PngTerminal()
			Options.outExtension = ".png"

		Options.terminal = terminal

		return parser, processor

			
	def parseSize(text):
		"Parses filter size value"
		if text == "":
			return None
		match = re.match("([0-9]+)([kmKM]?)", text)
		if match is None:
			return None
		mod = 1
		if match.group(2).upper() == "K":
			mod = 1024
		if match.group(2).upper() == "M":
			mod = 1024 * 1024
		return int(match.group(1)) * mod

	
	def parseTime(text):
		"Parses filter time value"
		match = re.match("([+]|)(?:([0-9]+):|)(?:([0-9]+):|)(?:([0-9]+)|)(?:\.([0-9]+)|)", text)
		if match is None:
			return None
		timestamp = 0
		print >> sys.stderr, "1:%s, 2:%s, 3:%s, 4:%s, 5:%s" % (match.group(1), match.group(2), match.group(3), match.group(4), match.group(5))
		if match.group(2):
			timestamp += int(match.group(2)) *  60 * 1000
		if match.group(3):
			timestamp *= 60
			timestamp += int(match.group(3)) * 60 * 1000
		if match.group(4):
			timestamp += int(match.group(4)) * 1000
		if match.group(5):
			timestamp += int(match.group(5).ljust(3, '0'))
		return match.group(1) and -timestamp or timestamp
	
	def updateFilter(filter, value):
		if Options.filterString is None:
			Options.filterString = ""
		else:
			Options.filterString += "; "
		Options.filterString += "%s=%s" % (filter, value)
	
	def displayUsage():
		print \
"""
Usage:
  rtrace-timeline <options>
  Where <options> are:
    -t         generate report of total resource allocations and
               non-free resources.
    -l         generate report of resource life times.
    -a         generate report of resource allocation/deallocation
               activity.
    -c         generate allocation count per resource size histogram.
    -s         generate total allocation size per resource size histogram.
    -S <msec>  the time slice for acivity report. By default it's 1/20th
               of the total time period (X axis range).
    -e         generate postscript (eps) file (png file is generated by default).
    -w         display interactive report window.
    -i <file>  input file.
    -o <file>  output file.
    
    --scale=<value>
    --scalex=<value>
    --scaley=<value>
        Scales the output image by the specified factor. The scale
        option affects both axis while scalex and scaley options
        affects X and Y axis respectively.

    --filter-<type>=[<value1>]-[<value2>]
        Sets the event filter where filter type can be:
          <size>  - filters events by allocation size. The size parameter
                    accepts postfix 'k' or 'm' specifying kilobytes or
                    megabytes. Filter examples: 
                      100-200  : from 100 to 200 bytes
                      10k-     : greater than 10 kbytes
                      -1m      : less than 1 mbyte
          <index> - filters events by their index. 
          <time>  - filters events by allocation/deallocation timestamp.
                    The timestamp format is [+][HH:][MM:][SS][.sss] where
                    HH - hours, MM - minutes, SS - seconds, sss - milliseconds
                    and '+' specifies relative timestamp. Relative timestamps
                    are counted either from the report beginning (the filter 
                    start value) or from the first event passing previous 
                    filters (the filter end value). Filter examples: 
                      10.5-12       : from 10.5 seconds to 12 seconds
                      10:00-+30     : from 10 minutes to 10 minutes 30 seconds
                      +1:00-+1:00   : from 1 minute since log start to 1 minute 
                                      duration 
                            
    Note that it's possible to generate multiple reports at the same time by
    specifying more than one report generation option (-t, -l -a). In this 
    mode output file (-o) should be always specified and the report filenames
    will have the follwing format:
      <filename>-<totals|activity|lifetime>.<eps|png> 
         where <filename> is the specified output file.                      
"""

		
	# static method definitions
	parse = staticmethod(parse)
	displayUsage = staticmethod(displayUsage)
	parseSize = staticmethod(parseSize)
	parseTime = staticmethod(parseTime)
	updateFilter = staticmethod(updateFilter)
# /class Options
	


# main()

# parse the command line options
parser, processor = Options.parse(sys.argv[1:])

# initialize processor and report generators
processor.initialize()

# read the input stream and prepare reports
parser.read(Options.streamIn)

# finish the reports
processor.finishReports()


