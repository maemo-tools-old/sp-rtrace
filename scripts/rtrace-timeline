#!/usr/bin/env python

# Copyright (C) 2010 by Nokia Corporation
#
# Contact: Eero Tamminen <eero.tamminen@nokia.com>
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License 
# version 2 as published by the Free Software Foundation. 
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301 USA

import sys, string, re, os, getopt, subprocess, operator

class Timestamp:
	"""
	This class provides timestamp utility functions.
	"""
	rxpTimestamp = re.compile("^([0-9]+)\:([0-9]+)\:([0-9]+)\.([0-9]+)$")

	def toString(hours, decimal = 3):
		"Converts integer timestamp (milliseconds since midnight) to text format HH:MM:SS.sss"
		msecs = hours % 1000		
		hours /= 1000
		seconds = hours % 60
		hours /= 60
		minutes = hours % 60
		hours /= 60  
		timestamp = "%02d:%02d:%02d" % (hours, minutes, seconds)
		if decimal > 0:
			for i in range (3 - decimal):
				msecs /= 10
			mask = ".%%0%dd" % decimal
			timestamp += mask % msecs
		return timestamp
	
	toString = staticmethod(toString)
	
	def offsetToString(offset):
		"Converts timestamp offset (milliseconds) to text format +[HH:][MM:][SS][.sss]"
		text = Timestamp.toString(offset)
		text = string.lstrip(text, ":0")
		text = string.rstrip(text, "0")
		if text[-1] == '.':
			text = string.rstrip(text, ".")
		if text == "" or text[0] == '.':
			text = "0" + text
		return text
	
	offsetToString = staticmethod(offsetToString)
	
	def fromString(text):
		"Converts text format timestamp HH:MM:SS.sss into integer value (milliseconds since midnight)"
		timestamp = 0
		match = Timestamp.rxpTimestamp.match(text)
		if match:
			timestamp = int(match.group(1)) * 3600000 + int(match.group(2)) * 60000 + int(match.group(3)) * 1000 + int(match.group(4))
		return timestamp

	fromString = staticmethod(fromString)
# /class Timestamp


class Context:
	"""
	This class contains allocation context implementation.
	"""
	# context masks 
	MASK_NONE = 0
	MASK_ALL = 0xFFFFFFFF
	
	# the context value/mask
	value = 0
	# the context name
	name = ""

	def __init__(self, value, name):
		self.value = value
		self.name = name

	def isMaskAll(self):
		"Checks if the context value covers all allocations ignoring their context"
		return self.value == Context.MASK_ALL
	
	def isMaskNone(self):
		"Checks if the context value is empty, masking allocations without contexts"
		return self.value == Context.MASK_NONE
# /class Context


class Resource:
	"""
	This class describes the tracked resource type.
	"""
	
	# the resource name
	type = None
	# flag indicating that reference counting mechanism is used for resource allocations
	refCounted = False
	
	def __init__(self, type, refCounted):
		self.type = type
		self.refCounted = refCounted
# /class Resource		

class Event:
	"""
	This class contains allocation/deallocation call event implementation.
	"""
	class Types:
		UNDEFINED = 0
		ALLOC = 1  
		FREE = 2
	# /class Types
		
	timestamp = 0
	res_size = 0
	res_id = ""
	type = Types.UNDEFINED
	context = 0
	index = 0
	
	def __init__(self, type, index, context, timestamp, res_id, res_size):
		self.type = type
		self.timestamp = timestamp
		self.res_size = res_size
		self.res_id= res_id
		self.context = context
		self.index = index
		
	def matchContext(self, context):
		"Checks if the event matches the specified context"
		if context.isMaskNone():
			if self.context != 0:
				return False
		elif not (context.isMaskAll() or (context.value & int(self.context, 16))):
				return False
		return True
# /class Event

class Filter:
	"""
	The base class for event filters.
	"""

	def matchesEvent(self, event):
		"Checks if the filter matches the event"
		return False
	
# /class Filter


class MinTimeFilter:
	"""
	Minimal event time filter, matching events with timestamp greater or equal.
	"""
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.timestamp >= self.value
# /class MinTimeFilter


class MaxTimeFilter:
	"""
	Maximal event time filter, matching events with timestamp less or equal.
	"""
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.timestamp <= self.value
# /class MaxTimeFilter


class MinTimeOffsetFilter:
	"""
	Minimal event time offset filter, matching events with relative timestamp greater or equal.
	The relative timestamp is counted from the first timestamp matching previous filters.
	"""
	value = 0
	offset = None
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		if self.offset is None:
			self.offset = event.timestamp
		return event.timestamp >= self.value + self.offset
# /class MinTimeOffsetFilter


class MaxTimeOffsetFilter:
	"""
	Maximal event time offset filter, matching events with relative tiemstamp less or equal.
	The relative timestamp is counted from the first timestamp matching previous filters.
	Practically it means log duration.
	"""
	value = 0
	offset = None
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		if self.offset is None:
			self.offset = event.timestamp
		return event.timestamp <= self.value + self.offset
# /class MaxTimeOffsetFilter

 
class MinSizeFilter(Filter):
	"""
	Minimal resource size filter, matching events with resource size grater or equal.
	"""		
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.type == Event.Types.FREE or event.res_size >= self.value
# /class MinSizeFilter		


class MaxSizeFilter(Filter):
	"""
	Maximal resource size filter, matching events with resource size less or equal.
	"""		
	value = 0
		
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.type == Event.Types.FREE or event.res_size <= self.value
# /class MaxSizeFilter		


class MinIndexFilter(Filter):
	"""
	Minimal event index filter, matching events with call record index greater or equal.
	"""		
	value = 0

	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.index >= self.value
# /class MinIndexFilter		


class MaxIndexFilter(Filter):
	"""
	Maximal event index filter, matching events with call record index less or equal.
	"""		
	value = 0
		
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return event.index <= self.value
# /class MaxIndexFilter		
			
class ContextFilter(Filter):
	"""
	Context filter, matching events with allocation context mathching the specified context.
	"""			
	value = 0
	
	def __init__(self, value):
		self.value = value
		
	def matchesEvent(self, event):
		return (self.value == 0 and event.context == 0) or (self.value & int(event.context))
# /class ContextFilter	
			
class Tic:
	"""
	This class provides helper functions for time slices used to represent
	time tics and activity slices.
	"""
	value = 0
	format = None
	text = None
	decimal = 0
		
	def __init__(self, slice, rounded):
		if rounded:
			round = 1
			value = slice
			self.value = 1
			while value != 0:
				self.value = value * round;
				round *= 10
				value /= 10
			#
		else: 
			self.value = slice
			
		self.decimal = 3
		slice = self.value
		while self.decimal and slice and slice % 10 == 0:
			self.decimal -= 1
			slice /= 10	
		self.format = "%%.%df" % self.decimal
	
	def getText(self):
		"Returns tic value converted into text format"
		if not self.text:
			self.text = self.format % (float(self.value) / 1000)
		return self.text	
	
# /class Tic

class Terminal:
	"""
	The base lass for terminal types.
	"""

	def init(self, file):
		"Writes terminal initialization data into configuration file"
		raise NotImplementedError()
	
	def finish(self, file):
		"Writes terminal uninitialization data into configuration file"
# /class Terminal	


class EpsTerminal(Terminal):
	"""
	Generates encapsulated postscrpipt file containing graphs
	"""
	
	def init(selfself, file):
		file.write("set terminal postscript eps enhanced color size %d,%d\n" % (Options.scaleX * 6, Options.scaleY * 4))
# /class PostscriptTerminal


class PngTerminal(Terminal):
	"""
	Generates png file containing graphs.
	"""

	def init(selfself, file):
		file.write("set terminal png enhanced size %d,%d\n" % (Options.scaleX * 1024, Options.scaleY * 728))
		file.write("set fontpath \"/usr/share/fonts/truetype/ttf-liberation\"\n")
# /class PostscriptTerminal
		

class WxtTerminal(Terminal):
	"""
	Displays output in a separate window ctreated by wxWidgets library.
	"""
	
	def init(self, file):
		file.write("set terminal wxt enhanced size 1024,728\n")
		
	def finish(self, file):
		file.write("pause -1 \"The graph is displayed in other window. Hit enter when you are finished viewing it...\\n\"\n")
# /class WxtTerminal

	
class Plotter:
	"""
	The plotter class provides high level API for creating gnuplot configuration file.
	
	The configuration file is created when creating Plotter instance and closed
	when the plot() method is called().
	"""
	
	class Table:
		"""
		The Table class provides table emulation with gnuplot labels.
		"""
		
		class Column:
			"""
			The Column class represents a single column in the table.
			"""
			
			class Cell:
				"""
				The Cell class represents a single cell in the column.
				"""
				text = None
				align = None
				
				def __init__(self, text, align = "right"):
					self.text = text
					self.align = align
		
				def write(self, file, row, col, size):
					"Writes cell contents at the specified coordinates"
					if self.align == "right":
						col += size - 1
					if self.align == "center":
						col += size / 2
					file.write("set label \"%s\" at character %d,%d %s\n" % (self.text, col, row, self.align))
				# /class Cell
			
			size = 0
			cells = None
			
			def __init__(self, size):
				self.size = size	
				self.cells = []
				
			def setCell(self, row, text, align):
				"Sets new cell containing text at the specified row"
				if row + 1 > len(self.cells):
					self.cells.extend(None for rows in range(row + 1 - len(self.cells)))
				self.cells[row] = self.Cell(text, align)
			
			def write(self, file, rows, col):
				"Writes column contents at the specified coordinates"
				for row in range(len(self.cells)):
					cell = self.cells[row]
					if cell is None:
						continue
					cell.write(file, rows - row, col, self.size)
				return self.size
		# /class Column
			
		rows = 0
		columns = None
		
		def __init__(self, row, col):
			self.row = row
			self.col = col
			self.columns = []
		
		def addColumn(self, width):
			"Adds a new column of the specified width"
			self.columns.append(self.Column(width))
		
		def setText(self, row, col, text, align = "right"):
			"Sets value of the cell at row,col with text"
			if col > len(self.columns):
				raise RuntimeError("Table.setText: column value(%d) exceeding column count(%d)" % (col, len(self.columns)))
			self.columns[col].setCell(row, text, align)
			if row > self.rows:
				self.rows = row
			
		def write(self, file):
			"Writes table into gnulot configuration file"
			offset = self.col
			for column in self.columns:
				offset += column.write(file, self.rows + self.row, offset)
	# /class Table
		
	class DataFile:
		"""
		This class represents gnuplot data file.
		"""
		
		# the target file name
		_filename = None
		
		def __init__(self, filename, title = None):
			self._filename = filename
			if title is not None:
				self.create(title)
			
		def create(self, title = None):
			"Creates data file and write title if specified"
			self.file = open(self._filename, "w")
			if self.file is None:
				raise RuntimeError("Failed to create data file: %s" % filename)
			if title is not None:
				self.file.write("Resource \"%s\"\n" % title)
			
		def write(self, x, y):
			"Writes a single graph point into data file"
			self.file.write("%d %d\n" % (x, y))
			
		def writeSeparator(self):
			self.file.write("\n")
			
		def writeText(self, value):
			"Writes text data into data file"
			self.file.write(value)
			
		def close(self):
			"Closes the file"
			self.file.close()
			
		def remove(self):
			"Deletes the target file"
			if os.path.isfile(self._filename):
				os.remove(self._filename)
			
		def getFilename(self):
			"Retrieves name of the target file"
			return self._filename
	# /class DataFile
	
	# the configuration file
	file = None
	# the tables to plot
	tables = None
	# the involved data files
	files = None
	# the output stream
	stream = None
	# the graphs to plot. Usually there is a one data file for one graph
	graphs = None
	# the last index of line style setting
	lineStyleIndex = 0
	# the plot id
	id = None
	# configuration file name
	cfgFilename = None
		
	def __init__(self, id):
		# initialize list values
		self.tables = []
		self.files = []
		self.graphs = []
		self.id = id
		self.cfgFilename = "timeline-%s.cfg" % id 
		
	def create(self):
		"Creates gnuplot configuration file"
		self.file = open(self.cfgFilename, "w")
		if self.file is None:
			print >> sys.stderr, "Failed to create configuration file: %s" % self.cfgFilename
			sys.exit(2)
	
		# initialize output terminal
		Options.terminal.init(self.file)

		self.stream = open("%s-%s%s" % (Options.outFilename, self.id, Options.outExtension), "w")
		
		# write graph legend outside graph
		self.file.write("set key bmargin\n")
		
	def setTitle(self, title):
		"Sets report title. The report title is printed at the top of the graph."
		self.file.write("set title \"%s" % title)
		if Options.filterString is not None:
			self.file.write("\\n(%s)" % Options.filterString)
		self.file.write("\"\n")
		
	def setStyle(self, style):
		self.file.write("set style %s\n" % style)

	def setAxisX(self, label, min = None, max = None, format = None, scale = None):
		"Sets X axis range (min-max) and formatting."

		# set ticks
		self.file.write("set xtics rotate nomirror\n")
		if scale is not None:
			self.file.write("set xtics scale %s\n" % scale)
			
		if min is not None:
			if min == max:
				max += 1
			range = max - min
			step = Tic(range / 10, True)
			tic = min - min % step.value
			if min % step.value > 0:
				tic += step.value
			min = tic
			
			# set label
			self.file.write("set xlabel \"%s\" offset 0,0\n" % label)
			# set  range
			self.file.write("set xrange[%d:%d]\n" % (min, max))
			# set the X axis tic label format, not used as tics are printed manually
			# file.write("set format x \"+%.3f\"\n")
	
			# place autotics outside range to avoid interference with manual tics
			self.file.write("set xtics %f,%f\n" % (max * 2, max * 2))
			
			while tic <= max - step.value:
				self.file.write("set xtics add (\"%s\\n+%s\" %d)\n" % (Timestamp.toString(tic, step.decimal), Timestamp.offsetToString(tic - min), tic))
				tic += step.value
			self.file.write("set xtics add (\"%s\\n+%s\" %d)\n" % (Timestamp.toString(max), Timestamp.offsetToString(range), max))
			
			
	def setAxisY(self, label, min, max, format):
		"Sets Y axis range (min-max) and formatting."
		if min == max:
			max += 1
		self.file.write("set yrange[%d:%d]\n" % (min, max))
		
		self.file.write("set format y \"%s\"\n" % format)
		self.file.write("set ytics out\n")
		
		self.file.write("set ylabel \"%s\"\n" % label)
	
	
	def setAxisY2(self, label, min, max, format = None):
		"Sets Y2 axis range and formatting."
		
		self.file.write("set y2range[%d:%d]\n" % (min, max))
		
		if format is not None:
			self.file.write("set format y2 \"%s\"\n" % format)
		self.file.write("set y2tics out\n")
		self.file.write("set ytics nomirror\n")
		
		self.file.write("set y2label \"%s\"\n" % label)

	def setBMargin(self, value):
		"Sets bottom margin value. Used to reserve space for statstics at the bottom of the page."
		self.file.write("set bmargin %d\n" % value)

	def addGraph(self, file, colX, colY, title = "\"\"", axis = None, style = None, prefix = None, ):
		"Adds a graph based on datafile file  to the plot. colX, colY identifies the "
		"columns containing data X/Y data."
		if len(self.graphs):
			data = ","
		else:
			data = ""
		if prefix is not None:
			data += prefix
		data += "\"%s\" using %s" % (file.getFilename(), colX)
		if colY is not None:
			data += ":%s" % (colY)
		if style is not None:
			data += " ls %d" % style
		data += " title %s" % title
		if axis:
			data += " axes %s" % axis
		data += "\\\n"
		self.graphs.append(data)
			
	def plot(self):
		"Sets the tables and plots the data files. The control/data file cleanup is performed afterwards."
		for table in self.tables:
			table.write(self.file)
			
		self.file.write("plot \\\n")
		for graph in self.graphs:
			self.file.write(graph)
		self.file.write("\n")

		Options.terminal.finish(self.file)
		
		self.file.close();
		
		# close data/configuration files
		for file in self.files:
			file.close()
		
		# Convert with gnuplot
		gnuplot = subprocess.Popen(["gnuplot", self.cfgFilename], 0, None, None, self.stream)
		gnuplot.wait()

		#self.cleanup()
	
	def setLineStyle(self, type, color):
		"Creates new line style and returns its index."
		self.lineStyleIndex += 1
		self.file.write("set style line %d" % self.lineStyleIndex)
		if type is not None:
			self.file.write(" lt %s" % type)
		if color is not None:
			self.file.write(" linecolor rgb \"%s\"" % color)
		self.file.write("\n")
		return self.lineStyleIndex
		
	def createTable(self, row, col):
		"""
		Creates virtual table object. The tables can be used to report statistics
		or whatever table formatted information is required. A gnuplot report can
		have multiple tables.
		"""
		table = self.Table(row, col)
		self.tables.append(table)
		return table
	
	def createFile(self, filename, title = None):
		"Creates new data file. This file will be automatically removed after plotting."
		file = self.DataFile(filename, title)
		self.files.append(file)
		return file
		
	def cleanup(self):
		"Deletes configuration and data files"
		os.remove(self.cfgFilename)
		
		for file in self.files:
			file.remove();
			
	def setKey(self, key):
		"Sets the data legend position."
		self.file.write("set key %s\n" % key)
		
	def setSeparator(self, value):
		"Sets the datafile separator character"
		self.file.write("set datafile separator \"%s\"\n" % value)

	
	def setGrid(self, value):
		"Sets the grid"	
		self.file.write("set grid %s\n" % value)
	
# /class Plotter	


#class Processor:
#	"""
#	The base class for report generators.
#	"""
#	
#	class Index:
#		"""
#		This class is used to index resources by their identifiers. It's 
#		used to minimize event lookups by resource identifier times.
#		"""
#		event = None
#		refCount = 0
#		
#		def __init__(self, event):
#			self.event = event
#			self.refCount = 1
#	# /class Index
#			
#	parser = None		
#
#	# resource overhead index used for allocation overhead estimation
#	overheadData = {"memory": 8}
#
#	def __init__(self, parser):
#		self.parser = parser
#		
#	def getId(self):
#		"Returns the report identifier. Used in output file templates when multiple "
#		"reports are requested."
#		raise NotImplementedError()
#	
#	def generateReport(self, stream):
#		"Generates report."
#		plotter = Plotter(stream, Options.terminal)
#		self.writeReport(plotter)
#		
#	def writeReport(self, plotter):
#		"Writes the end report. This function must be overloaded by report generators to "
#		"provide report generation functionality."
#		raise NotImplementedError()
#		
#	def isEventInRange(self, event):
#		"Checks if the event matches the filters specified in Options."
#		for filter in Options.filters:
#			if not filter.matchesEvent(event):
#				return False
#		return True
#				
## /class Processor		
		
#class HistogramProcessor(Processor):
#	"""
#	The HistogramProcessor generates statistics about allocation count/total size per
#	resource size.
#	The generated report type (count or size) depends on the mode parameter passed
#	in constructor.
#	"""
#	mode = None
#	
#	class Alloc:
#		total = 0
#		freed = 0
#	# /class Alloc
#	
#	class Stats:
#		"Stores allocation (freed/unfreed) statistics"
#		count = 0
#		total = 0
#		allocs = None
#	
#		def __init__(self):
#			self.allocs = []
#			
#		def getMedian(self):
#			"Calculates median allocation size"
#			nallocs = len(self.allocs)
#			return nallocs and self.allocs[nallocs / 2] or 0
#	# /class Stats
#		
#	def __init__(self, parser, mode):
#		Processor.__init__(self, parser)
#		self.mode = mode
#		
#	def getId(self):
#		"Returns the stats report id"
#		return "histogram-%s" % self.mode
#
#	def writeReport(self, plotter):
#		"Writes the histogram report"
#
#		yrangeMax = 0
#			
#		# histogram data: size -> resource -> context
#		data = {}
#		
#		# Histogram reports supports only single resource. 
#		# Show a warning message and exit otherwise.
#		if len(self.parser.events) > 1:
#			resources = ""
#			for resource in self.parser.events:
#				if resources != "":
#					resources += ", "
#				resources += resource
#			print >> sys.stderr, "WARNING: multiple resources (%s) detected, the results might be misleading.\n"\
#			                     "Use --filter-resource options to filter a single resource." % resources
#			sys.exit(-1)
#			
#		# iterate through registered resources
#		for resource in self.parser.events:
#			events = self.parser.events[resource]
#			index = {}
#			
#			# iterate through events
#			for event in events:
#				# skip events not matching context/filters
#				if not self.isEventInRange(event):
#					continue
#					
#				if event.type == Event.Types.ALLOC:
#					if event.res_id in index:
#						# resource is already indexed, increase reference counter
#						index[event.res_id].refCount += 1
#						continue
#					else:
#						# index the event by resource id.
#						index[event.res_id] = self.Index(event);
#						
#						# store histogram statistics
#						if event.res_size not in data:
#							data[event.res_size] = {}
#						if resource not in data[event.res_size]:
#							data[event.res_size][resource] = self.Alloc()
#						data[event.res_size][resource].total += 1
#						
#				if event.type == Event.Types.FREE:
#					if event.res_id not in index:
#						# ignore resources allocation of which was not registered
#						continue
#					# decrement resource reference counter
#					ievent = index[event.res_id]
#					ievent.refCount -= 1
#
#					# check if the resource was really deleted						
#					if ievent.refCount == 0:
#						data[ievent.event.res_size][resource].freed += 1
#						# remove deleted resource from index.
#						del index[event.res_id]
#
#			# check if the data was gathered 
#			if len(data) == 0:
#				print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
#				                     "or no events are matching the specified filter."
#				plotter.cleanup()
#				sys.exit(0)
#			
#		# initialize statistics data
#		statsFreed = self.Stats()
#		statsUnfreed = self.Stats()
#		statsSumm = self.Stats()
#		
#		# index by size
#		keys = []				
#		for size in data:
#			keys.append(size)
#		keys.sort()
#
#
#		# calculate median values
#		for size in keys:
#			for resource in self.parser.events:
#				alloc = data[size][resource]
#				for index in range(0, alloc.freed):
#					statsFreed.allocs.append(size)
#					statsSumm.allocs.append(size)
#				for index in range(0, alloc.total - alloc.freed):
#					statsUnfreed.allocs.append(size)
#					statsSumm.allocs.append(size)
#	
#		# create data file.
#		fileData = plotter.createFile("timeline.dat")
#		fileData.create()
#		
#		# create line styles for freed and unfreed bars
#		ltUnfreed = plotter.setLineStyle(None, "#FF0000")
#		ltFreed = plotter.setLineStyle(None, "#00FF00")
#		
#		# write data header 
#
#		# Histogram data starts with second column (the first column contains
#		# allocation size).
#		index = 2
#		fileData.writeText("size")
#		for resource in self.parser.events:
#			plotter.addGraph(fileData, "%d" % index, "xtic(1)", "\"%s allocation %s (unfreed)\"" % (resource, self.mode), \
#							 None, ltUnfreed, "newhistogram \"Resource size\", ")
#			plotter.addGraph(fileData, "%d" % (index + 1), "xtic(1)", "\"%s allocation %s (freed)\"" % (resource, self.mode), None, ltFreed)
#			index += 2
#		fileData.writeText("\n")
#		
#		# write data		
#		for size in keys:
#			fileData.writeText("%d" % size)	
#			for resource in self.parser.events:
#				alloc = data[size][resource]
#				if alloc is None:
#					fileData.writeText("\t-\t-")
#				else:
#					unfreed = alloc.total - alloc.freed
#					if self.mode == "count":
#						fileData.writeText("\t%d\t%d" % (unfreed, alloc.freed))
#						if yrangeMax < alloc.total:
#							yrangeMax = alloc.total
#					else:
#						fileData.writeText("\t%d\t%d" % ((int(size) * unfreed), int(size) * alloc.freed))
#						if yrangeMax < alloc.total * int(size):
#							yrangeMax = alloc.total * int(size)
#					
#					# calculate statistics
#					statsFreed.count += alloc.freed
#					statsFreed.total += alloc.freed * int(size)
#					
#					statsUnfreed.count += unfreed
#					statsUnfreed.total += unfreed * int(size)
#							
#			fileData.writeText("\n")
#			
#		fileData.close()
#		
#		# set the plot properties
#		if self.mode == "size":
#			ylabel = "Total allocation size"
#			title = "Total allocation size per resource size"
#		else:
#			ylabel = "Allocation count"
#			title = "Allocation count per resource size"
#		plotter.setTitle(title)
#		plotter.setAxisY(ylabel, 0, yrangeMax, "%.1s%c")
#		plotter.setGrid("ytics")
#		plotter.setAxisX("Resource size", None, None, None, "0")
#		plotter.setStyle("data histogram")
#		plotter.setStyle("histogram rowstacked")
#		plotter.setStyle("fill solid 0.2")
#		plotter.setSeparator("\\t")
#
#		# write statistics table
#
#		# define table headers
#		table = plotter.createTable(1, 1)
#		# name column
#		table.addColumn(10)
#		# median
#		table.addColumn(12)
#		# allocation count
#		table.addColumn(10)
#		# allocation size
#		table.addColumn(12)
#
#		table.setText(0, 0, "Allocs", "center")
#		table.setText(0, 1, "Median", "center")
#		table.setText(0, 2, "Count", "center")
#		table.setText(0, 3, "Total Size", "center")
#		
#		table.setText(2, 0, "freed", "right")
#		table.setText(3, 0, "unfreed", "right")
#		table.setText(4, 0, "both", "right")
#
#		table.setText(2, 1, "%d" % statsFreed.getMedian())
#		table.setText(3, 1, "%d" % statsUnfreed.getMedian())
#		table.setText(4, 1, "%d" % statsSumm.getMedian())
#		
#		table.setText(2, 2, "%d" % statsFreed.count)
#		table.setText(3, 2, "%d" % statsUnfreed.count)
#		table.setText(4, 2, "%d" % (statsFreed.count + statsUnfreed.count))
#
#		table.setText(2, 3, "%d" % statsFreed.total)
#		table.setText(3, 3, "%d" % statsUnfreed.total)
#		table.setText(4, 3, "%d" % (statsFreed.total + statsUnfreed.total))
#		
#		plotter.setBMargin(10)
#		plotter.setKey("invert")
#		
#		plotter.plot()
#	
## /class HistogramProcessor


#class LifetimeProcessor(Processor):
#	"""
#	The LifetimeProcessor class generates resource life time
#	report. This report contains lines displaying resource
#	allocation and release times.
#	"""
#
#	class Writer():
#		"""
#		Base class for lifetime graph writers.
#		The lifetime graphs has two resolution levels - event resolution
#		and context resolution.
#		Event resolution is used when log contains limited amount of resources
#		and each resource can be displayed in a different style and color. 
#		Context resolution is used when log contains a large amount of resources
#		and marking each resource with different style would only make a mess. 
#		In this case resources are colored by their allocation contexts.
#		"""
#		# the data file
#		_file = None
#		# a reference to the plotter
#		_plotter = None
#		
#		def __init__(self, plotter):
#			self._plotter = plotter
#			
#		def prepareContext(self, resource, context):
#			"Prepares (creates and adds to plotter) context resolution data file."
#			return self._file
#	
#		def prepareEvent(self, resource, event):
#			"Prepares (creates and adds to plotter) event resolution data file."
#			return self._file
#		
#		def flushContext(self):
#			"Flushes context resolution data file (simply closes it)."
#			pass
#		
#		def flushEvent(self):
#			"Flushes event resolution data file (simply closes it)."
#			pass
#		
#	# /class Writer
#		
#	class ContextWriter(Writer):
#		"""
#		Context resolution graph writer.
#		"""
#		def prepareContext(self, resource, context):
#			self._file = self._plotter.createFile("%s-%x.dat" % (resource, context.value), "%s (%s)" % (resource, context.name))	
#			self._plotter.addGraph(self._file, "1", "2", "column(2)")
#			return self._file
#		
#		def flushContext(self):
#			self._file.close()
#	# /class ContextWriter
#			
#	class EventWriter(Writer):
#		"""
#		Event resolution graph writer.
#		"""
#		def prepareEvent(self, resource, event):
#			self._file = self._plotter.createFile("%s-%d.dat" % (resource, event.index), "%s (%s)" % (resource, event.res_id))	
#			self._plotter.addGraph(self._file, "1", "2", "column(2)")
#			return self._file
#		
#		def flushEvent(self):
#			self._file.close()
#	# /class EventWriter
#		
#	class Stats:
#		"""
#		Resource lifetime statistics.
#		"""
#		class Data:
#			"""
#			Resource lifetime statistics data.
#			"""
#			# allocation sie
#			size = 0
#			# number of allocations of this size
#			count = 0
#			# time of the first allocation of this size
#			timestamp = 0
#			
#			def __init__(self):
#				pass
#		# /class Data
#		
#		# the minimal allocation size statistics
#		min = None
#		# the maximal allocation size statistics
#		max = None
#		
#		def __init__(self):
#			self.min = self.Data()
#			self.max = self.Data()
#			self.min.size = sys.maxint
#	# /class Stats
#		
#	# Amount of allocations that separates event view from resolution view.
#	# If the log contains less than DETAILS_LIMIT allocations the event resolution is used.
#	# Otherwise the context resolution is used.
#	DETAILS_LIMIT = 20
#
#	def getId(self):
#		"Returns the lifetime report id"
#		return "lifetime"
#
#	def writeReport(self, plotter):
#		"Writes the lifetime report"
#		# reset X,Y axis range
#		xrangeMin = None
#		xrangeMax = 0
#		yrangeMin = 0
#		yrangeMax = 0
#		
#		# count the total number of allocations to choose resolution
#		totalAllocs = 0
#		for resource in self.parser.events.keys():
#			for event in self.parser.events[resource]:
#				if event.type == Event.Types.ALLOC and self.isEventInRange(event):
#					totalAllocs += 1
#
#		if totalAllocs == 0:
#			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
#				                     "or no events are matching the specified filter."
#			sys.exit(0)
#		
#		# initialize context filters
#		contexts = [Context(Context.MASK_ALL, "all allocations")]
#		
#		if totalAllocs > self.DETAILS_LIMIT:
#			# switch to context resolution mode and populate context filter array
#			writer = self.ContextWriter(plotter)
#			if len(self.parser.contexts) > 0:
#				contexts.append(Context(Context.MASK_NONE, "no contexts"))
#				contexts.extend(self.parser.contexts)
#		else:
#			# switch to event resolution mode
#			writer = self.EventWriter(plotter)
#			
#		stats = {}
#		
#		# iterate through registered resources
#		for resource in self.parser.events.keys():
#			# initialize resource statistics data
#			events = self.parser.events[resource]
#			# resource indexing map 
#			index = {}
#			# initialize resource statistics
#			stat = self.Stats()
#			stats[resource] = stat
#			
#			# iterate through context filters
#			for context in contexts:
#				file = writer.prepareContext(resource, context)
#				allocs = []
#				total = 0
#				
#				# iterate through events
#				for event in events:
#					# skip events not matching context/filters
#					if not event.matchContext(context):
#						continue
#					if not self.isEventInRange(event):
#						continue
#					# update X axis range values
#					if xrangeMin is None:
#						xrangeMin = event.timestamp
#					if xrangeMax < event.timestamp:
#						xrangeMax = event.timestamp
#						
#					if event.type == Event.Types.ALLOC:
#						if event.res_id in index:
#							# resource is already indexed, increase reference counter
#							index[event.res_id].refCount += 1
#							continue
#						else:
#							# index the event by resource id.
#							index[event.res_id] = self.Index(event);
#							allocs.append(event.res_size)
#							total += event.res_size
#
#							# update Y axis range value
#							size = event.res_size
#							if size > yrangeMax:
#								yrangeMax = size
#							
#							# gather statistics
#							if event.res_size < stat.min.size:
#								stat.min.size = event.res_size
#								stat.min.count = 0
#								stat.min.timestamp = event.timestamp
#							if event.res_size == stat.min.size:
#								stat.min.count += 1
#							if event.res_size > stat.max.size:
#								stat.max.size = event.res_size
#								stat.max.count = 0
#								stat.max.timestamp = event.timestamp
#							if event.res_size == stat.max.size:
#								stat.max.count += 1
#								
#							
#					if event.type == Event.Types.FREE:
#						if event.res_id not in index:
#							# ignore resources allocation of which was not registered
#							continue
#						# decrement resource reference counter
#						ievent = index[event.res_id]
#						ievent.refCount -= 1
#
#						# check if the resource was really deleted						
#						if ievent.refCount == 0:
#							file = writer.prepareEvent(resource, ievent.event)
#							# plot the resource lifetime
#							file.write(ievent.event.timestamp, ievent.event.res_size)
#							file.write(event.timestamp, ievent.event.res_size)
#							file.writeSeparator()
#							#
#							writer.flushEvent()
#							
#							# remove deleted resource from index.
#							del index[event.res_id]
#	
#				# Adjust X axis range to contain at least single point
#				if xrangeMax == xrangeMin:
#					xrangeMax += 1
#					
#				# plot all allocated, but not freed resources					
#				for res_id, ievent in index.iteritems():
#					file = writer.prepareEvent(resource, ievent.event)
#					file.write(ievent.event.timestamp, ievent.event.res_size)
#					file.write(xrangeMax, ievent.event.res_size)
#					file.writeSeparator()
#					writer.flushEvent()
#
#				# calculate statistics - average and median values
#				allocs.sort()
#				totals = len(allocs)
#				statAverage = total / totals;
#				statMedian = totals and allocs[totals / 2 - 1] or 0
#				if totals % 2 == 0:
#					statMedian = (statMedian + allocs[totals / 2]) / 2
#					
#				# plot the statistics lines
#				file = plotter.createFile("%s-%x-average" % (resource, context.value), "%s (average:%d)" % (resource, statAverage))
#				plotter.addGraph(file, "1", "2", "column(2)")
#				file.write(xrangeMin, statAverage)
#				file.write(xrangeMax, statAverage)
#				file.close();
#				file = plotter.createFile("%s-%x-median" % (resource, context.value), "%s (median:%d)" % (resource, statMedian))
#				plotter.addGraph(file, "1", "2", "column(2)")
#				file.write(xrangeMin, statMedian)
#				file.write(xrangeMax, statMedian)
#				file.close();
#		
#				writer.flushContext()
#	
#		# increase Y  range, so the top graph isn't hidden beyond the axis	
#		yrangeMax = yrangeMax * 105 / 100	
#
#		plotter.setTitle("Resource life-time")
#		plotter.setAxisX("time (secs)", xrangeMin, xrangeMax)
#		plotter.setAxisY("size", yrangeMin, yrangeMax, "%.1s%c")
#		
#		if totalAllocs > self.DETAILS_LIMIT:
#			plotter.setStyle("data lines")
#		else:
#			plotter.setStyle("data linespoints")
#			
#		# define table headers
#		table = plotter.createTable(1, 1)
#		# resource name column
#		table.addColumn(10)
#		# snapshot name
#		table.addColumn(5)
#		# allocation count
#		table.addColumn(8)
#		# allocation size
#		table.addColumn(10)
#		# timestamp
#		table.addColumn(12)
#
#		table.setText(0, 0, "Resource", "center")
#		table.setText(0, 1, "State", "center")
#
#		table.setText(0, 2, "Size", "center")
#		table.setText(0, 3, "Count", "center")
#		table.setText(0, 4, "Time", "center")
#
#		# write statistics data
#		resourceIndex = 2
#		for resource in self.parser.events.keys():
#			stat = stats[resource]
#			table.setText(resourceIndex, 0, resource, "left")
#			table.setText(resourceIndex, 1, "min", "center")
#			table.setText(resourceIndex, 2, "%d" % stat.min.size)
#			table.setText(resourceIndex, 3, "%d" % stat.min.count)
#			table.setText(resourceIndex, 4, "%s" % Timestamp.toString(stat.min.timestamp))
#
#			resourceIndex += 1
#			table.setText(resourceIndex, 1, "max", "center")
#			table.setText(resourceIndex, 2, "%d" % stat.max.size)
#			table.setText(resourceIndex, 3, "%d" % stat.max.count)
#			table.setText(resourceIndex, 4, "%s" % Timestamp.toString(stat.max.timestamp))
#			
#			resourceIndex += 2
#		
#		# Reserve space at the bottom for statistics data
#		bmargin = len(contexts) + 9
#		if bmargin < 9 + table.rows:
#			bmargin = 9 + table.rows
#		if bmargin < 15:
#			bmargin = 15
#			
#		# if the legend contains too many graphs - write it at the left side instead of the bottom.
#		if totalAllocs < self.DETAILS_LIMIT and bmargin < totalAllocs + 5:
#			plotter.setKey("right outside")
#			
#		plotter.setBMargin(bmargin)
#
#		plotter.plot()
## /class LifetimeProcessor	

		
class ReportGenerator:
	"""
	The base class for all report generators.
	"""
	# the resource identifier
	_id = None
	# the plotter 
	_plotter = None

	# resource allocation overhead data
	overheadData = {"memory": 8}

	def __init__(self, id):
		self._id = id
		self.plotter = Plotter(id)
		
	def getId(self):
		return self._id

	def initialize(self):
		"Initializes generator. As options aren't fully processed during __init__, the initialize() "
		"method can be used to initialize options dependant resources."

	def processEventInContext(self, resource, context, event, allocData):
		""
		raise NotImplementedError()
	
	def finish(self):
		"Finishes report"
		raise NotImplementedError()
#/class ReportGenerator		


class LifetimeGenerator(ReportGenerator):
	"""
	The LifetimeGenerator class generates resource life time
	report. This report contains lines displaying resource
	allocation and release times.
	"""

	class Stats:
		"""
		Resource lifetime statistics.
		"""
		class Data:
			"""
			Resource lifetime statistics data.
			"""
			# allocation sie
			size = 0
			# number of allocations of this size
			count = 0
			# time of the first allocation of this size
			timestamp = 0
			
			def __init__(self):
				pass
		# /class Data
		
		# the minimal allocation size statistics
		min = None
		# the maximal allocation size statistics
		max = None
		
		def __init__(self):
			self.min = self.Data()
			self.max = self.Data()
			self.min.size = sys.maxint
	# /class Stats
	
	
	class ContextData:
		"Context data container"
		fileLifetime = None
		total = 0
		allocs = None
		
		def __init__(self, file):
			self.fileLifetime = file
			self.allocs = []
	
	class ResourceData:
		"Resource data container"
		stats = None
		contexts = None
		
		def __init__(self):
			self.stats = LifetimeGenerator.Stats()
			self.contexts = {}
	#/class ResourceData

	# axis range
	xrangeMin = None
	xrangeMax = 0
	yrangeMin = 0
	yrangeMax = 0
	
	#
	totalLifelines = 0
	DETAILS_LIMIT = 20
	
	def __init__(self):
		ReportGenerator.__init__(self, "lifetime")
		self.stats = {}
		self.data = {}

		self.stats = {}
		self.data = {}


	def processEventInContext(self, resource, context, event, allocData):
		# create data containers if necessary
		if resource not in self.data:
			self.data[resource] = self.ResourceData()
			
		if context.value not in self.data[resource].contexts:
			file = self.plotter.createFile("%s-%s-context-%x.dat" % (self.getId(), resource, context.value), "%s (%s)" % (resource, context.name))
			self.data[resource].contexts[context.value] = self.ContextData(file)
			
		resourceData = self.data[resource]
		contextData = resourceData.contexts[context.value]
		stats = resourceData.stats
		
		if self.xrangeMin is None:
			self.xrangeMin = event.timestamp
		if self.xrangeMax < event.timestamp:
			self.xrangeMax = event.timestamp
			
		if event.type == Event.Types.ALLOC:
			# index the event by resource id.
			contextData.allocs.append(event.res_size)
			contextData.total += event.res_size

			# update Y axis range value
			size = event.res_size
			if size > self.yrangeMax:
				self.yrangeMax = size
				
			# gather statistics
			if event.res_size < stats.min.size:
				stats.min.size = event.res_size
				stats.min.count = 0
				stats.min.timestamp = event.timestamp
			if event.res_size == stats.min.size:
				stats.min.count += 1
			if event.res_size > stats.max.size:
				stats.max.size = event.res_size
				stats.max.count = 0
				stats.max.timestamp = event.timestamp
			if event.res_size == stats.max.size:
				stats.max.count += 1
					
		if event.type == Event.Types.FREE:
			contextData.fileLifetime.write(allocData.timestamp, allocData.size)
			contextData.fileLifetime.write(event.timestamp, allocData.size)
			contextData.fileLifetime.writeSeparator()
			
			if self.totalLifelines < self.DETAILS_LIMIT:
				file = self.plotter.createFile("%s-%s-%d.dat" % (self.getId(), resource, event.index), "%s (%s)" % (resource, event.res_id))
				file.write(allocData.timestamp, allocData.size)
				file.write(event.timestamp, allocData.size)
				file.writeSeparator()
			
			self.totalLifelines += 1
			
		
	
# /class LifetimeGenerator

class ActivityGenerator(ReportGenerator):
	"""
	The ActivityGenerator class generates 'activity' report.
	The activity report contains graphs displaying the resource allocation rate per time slice.
	The allocation rate is calculated by going through events by time based steps and calculating
	the allocation rate for each step by dividing the total allocation size with total allocation
	number for all allocations during the last time slice period. 
	Usually the step value is set to half of the specified time slice.
	"""

	class Stats:
		"""
		Resource allocation activity statistics 
		"""
		class Data:
			count = 0
			size = 0
			timestamp = 0
			file = None
		# /class Data

		peakSize = None
		peakAllocs = None
		peakFrees = None
		
		def __init__(self):
			self.peakSize = self.Data()
			self.peakAllocs = self.Data()
			self.peakFrees = self.Data()

		def update(self, contextData, timestamp):			
			if contextData.total > self.peakSize.size:
				self.peakSize.size = contextData.total
				self.peakSize.count = contextData.allocs
				self.peakSize.timestamp = timestamp
			if contextData.allocs > self.peakAllocs.count:
				self.peakAllocs.size = contextData.total
				self.peakAllocs.count = contextData.allocs
				self.peakAllocs.timestamp = timestamp
			if contextData.frees > self.peakFrees.count:
				self.peakFrees.count = contextData.frees
				self.peakFrees.size = contextData.total
				self.peakFrees.timestamp = timestamp
			
	# /class Stats

	class ContextData:
		"Data files used for single resource-context graph"
		fileRate = None
		fileAllocs = None
		fileFrees = None
		
		# statistics data
		total = 0
		allocs = 0
		frees = 0
		
		# slice data
		sliceEvents = None
		
		def __init__(self, fileRate, fileAllocs, fileFrees):
			self.fileRate = fileRate
			self.fileAllocs = fileAllocs
			self.fileFrees = fileFrees
			
			self.sliceEvents = []
	
		def processSlice(self, timestamp, slice, stats):		
			# remove old events
			while len(self.sliceEvents) > 0 and self.sliceEvents[0].timestamp < timestamp - slice:
				oldEvent = self.sliceEvents.pop(0)
				if oldEvent.type == Event.Types.ALLOC:
					self.total -= oldEvent.res_size
					self.allocs -= 1
				if oldEvent.type == Event.Types.FREE:
					self.frees -= 1
			
			# write graphs
			self.fileRate.write(timestamp, self.total)
			self.fileAllocs.write(timestamp, self.allocs)
			self.fileFrees.write(timestamp, self.frees)

		def addEvent(self, event):
			if event.type == Event.Types.ALLOC:
				self.total += event.res_size
				self.allocs += 1
			if event.type == Event.Types.FREE:
				self.frees +=1
			self.sliceEvents.append(event)

			
	# /class ContextData

	class ResourceData:
		stats = None
		contexts = None
		
		def __init__(self):
			self.stats = ActivityGenerator.Stats();
			self.contexts = {}
		
	# /class ResourceData

	# the time slice (20 seconds by default) 
	slice = None
	step = 0
	
	# axis range
	yrangeMin = 0
	yrangeMax = 0
	y2rangeMin = 0
	y2rangeMax = 0
	xrangeMin = None
	xrangeMax = 0

	# data files
	data = None
	
	# the current time slice value
	sliceTimestamp = None
	
		
	def __init__(self):
		ReportGenerator.__init__(self, "activity")
		self.data = {}


	def initialize(self):
		#
		self.slice = Tic(Options.slice or 20000, False)
		# calculate step value for statistics checkpoints
		self.step = self.slice.value / 2
		if self.step < 1:
			self.step = 1

	def updateRangeY(self, contextData):
		# update Y, Y2 axis ranges
		if contextData.total > self.yrangeMax:
			self.yrangeMax = contextData.total
		if contextData.allocs > self.y2rangeMax:
			self.y2rangeMax = contextData.allocs
		if contextData.frees > self.y2rangeMax:
			self.y2rangeMax = contextData.frees
			
	def updateRangeX(self, timestamp):
		if self.xrangeMin is None:
			self.xrangeMin = timestamp
		if timestamp > self.xrangeMax:
			self.xrangeMax = timestamp
	
	def processEventInContext(self, resource, context, event, allocData):
		# update X axis range
		self.updateRangeX(event.timestamp)
		
		# create data containers if necessary
		if resource not in self.data:
			self.data[resource] = self.ResourceData()
			
		if context.value not in self.data[resource].contexts:
			fileRate = self.plotter.createFile("%s-%s-size-%x.dat" % (self.getId(), resource, context.value), \
												"%s (rate:%s)" % (resource, context.name))
			fileRate.write(self.xrangeMin, 0)
			fileAllocs = self.plotter.createFile("%s-%s-allocs-%x.dat" % (self.getId(), resource, context.value),\
												"%s (allocs:%s)" % (resource, context.name))
			fileAllocs.write(self.xrangeMin, 0)
			fileFrees = self.plotter.createFile("%s-%s-frees-%x.dat" % (self.getId(), resource, context.value),\
											 	"%s (frees:%s)" % (resource, context.name))
			fileFrees.write(self.xrangeMin, 0)
			
			self.data[resource].contexts[context.value] = self.ContextData(fileRate, fileAllocs, fileFrees)

		resourceData = self.data[resource]
		contextData = resourceData.contexts[context.value]
		stats = resourceData.stats

			
		if self.sliceTimestamp is None:
			self.sliceTimestamp = event.timestamp
	
		timestamp = self.sliceTimestamp + self.step
		
		# process timeslice if the event timestamp is beyond it
		if timestamp <= event.timestamp:
			contextData.processSlice(timestamp, self.slice.value, stats)
		
			# store peak values
			if context.isMaskAll():
				stats.update(contextData, timestamp)

			# update Y axis range	
			self.updateRangeY(contextData)
			
			# update slice timestamp
			self.sliceTimestamp = timestamp

		# add event to the timeslice
		contextData.addEvent(event)		
			
	
	def finish(self):
		""
		
		# number of graphs (without counting overhead data)
		ngraphs = 0

		# find the the timestamp for the last slice
		timestamp = self.sliceTimestamp + self.step
		self.updateRangeX(timestamp)

		# calculate last slice data
		for resource in self.data:
			resourceData = self.data[resource]
			stats = resourceData.stats
			for context in resourceData.contexts:
				contextData = resourceData.contexts[context]
				contextData.processSlice(timestamp, self.slice.value, stats)
				
		# update Y axis range	
		self.updateRangeY(contextData)

		# Check if the gathered data is not empty
		if self.yrangeMax == 0:		
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			self.plotter.cleanup()
			sys.exit(0)
	
		# increase Y range, so top graph isn't hidden beyond the axis	
		self.yrangeMax = self.yrangeMax * 105 / 100

		for resource in self.data:
			resourceData = self.data[resource]
			stats = resourceData.stats
			for context in resourceData.contexts:
				# store peak values
				if context == 0xFFFFFFFF:
					stats.update(contextData, timestamp)
				
				self.plotter.addGraph(contextData.fileRate, "1", "2", "column(2)")
				self.plotter.addGraph(contextData.fileAllocs, "1", "2", "column(2)", "x1y2")
				self.plotter.addGraph(contextData.fileFrees, "1", "2", "column(2)", "x1y2")
				ngraphs += 3

			# plot the peak markers
			file = self.plotter.createFile("%s-%s-size-peak.dat" % (self.getId(), resource), \
										"%s (peak rate:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakSize.timestamp, self.yrangeMin)
			file.write(stats.peakSize.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")
	
			file = self.plotter.createFile("%s-%s-allocs-peak.dat" % (self.getId(), resource), \
										"%s (peak allocs:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakAllocs.timestamp, self.yrangeMin)
			file.write(stats.peakAllocs.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")

			file = self.plotter.createFile("%s-%s-frees-peak.dat" % (self.getId(), resource),
										"%s (peak frees:%s)" % (resource, Timestamp.toString(timestamp)))
			file.write(stats.peakFrees.timestamp, self.yrangeMin)
			file.write(stats.peakFrees.timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")

		#	
		# generate gnuplot configuration file:
		#
		self.plotter.create()
		self.plotter.setTitle("Allocation/deallocation rate")
		
		self.plotter.setAxisX("time (secs)", self.xrangeMin, self.xrangeMax)
		self.plotter.setAxisY("amount per %s sec" % self.slice.getText(), self.yrangeMin, self.yrangeMax, "%.1s%c")
		self.plotter.setAxisY2("count per %s sec" % self.slice.getText(), self.y2rangeMin, self.y2rangeMax)
			
		self.plotter.setStyle("data lines")
		
		# Write summary report
		
		# define table headers
		table = self.plotter.createTable(1, 1)
		# resource name column
		table.addColumn(10)
		# snapshot name column
		table.addColumn(10)
		# allocation count
		table.addColumn(8)
		# allocation size
		table.addColumn(10)

		table.setText(0, 0, "Resource", "center")
		table.setText(0, 1, "State", "center")

		table.setText(0, 2, "Count", "center")
		table.setText(0, 3, "Size", "center")

		# write summary data
		resourceIndex = 2
		for resource in self.data:
			stats = self.data[resource].stats
			table.setText(resourceIndex, 0, resource, "left")
			table.setText(resourceIndex, 1, "peak size", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakSize.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakSize.size)

			resourceIndex += 1
			table.setText(resourceIndex, 1, "peak allocs", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakAllocs.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakAllocs.size)
			
			resourceIndex += 1
			table.setText(resourceIndex, 1, "peak frees", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakFrees.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakFrees.size)
			
			resourceIndex += 2
		
		# Reserve space at the bottom for leak data
		bmargin = ngraphs + 9
		if bmargin < 9 + table.rows:
			bmargin = 9 + table.rows
		if bmargin < 15:
			bmargin = 15
		self.plotter.setBMargin(bmargin)
		
		# plot the data files
		self.plotter.plot()

		

# /class ActivityGenerator


class TotalsGenerator(ReportGenerator):
	"""
	The TotalsGenerator class generates 'totals' report.
	The 'totals' report contains graph displaying the total resource allocation over the time.
	"""
	class Stats:
		"""
		Resource allocation statistics 
		"""
		class Data:
			count = 0
			size = 0
		# /class Data
		
		# 'leaked' allocations at the end of report
		endLeaks = None
		# 'leaked' allocations at the peak time
		peakLeaks = None
		# total allocations at the end of report
		endTotals = None
		# total allocations at the peak time
		peakTotals = None
		# peak allocation timestamp
		peakTimestamp = 0

		def __init__(self):
			# non-freed allocations at the end of trace
			self.endLeaks = self.Data()
			# non-freed allocations at the peak time
			self.peakLeaks = self.Data()
			# total allocations at the end of trace
			self.endTotals = self.Data()
			# total allocations at the peak time
			self.peakTotals = self.Data()
	# /class Stats
	

	class ContextData:
		fileTotals = None
		total = 0
		
		def __init__(self, fileTotals):
			self.fileTotals = fileTotals
	# /class ContextData
	
	class ResourceData:
		"Data files used for single resource-context graph"
		
		overhead = 0
		fileOverhead = None

		contexts = None
				
		def __init__(self, fileOverhead):
			self.fileOverhead = fileOverhead
			self.contexts = {}
			self.stats = TotalsGenerator.Stats()
	# /class ResourceData


	# Axis range
	xrangeMin = None
	xrangeMax = 0
	yrangeMin = 0
	yrangeMax = 0
	
	#
	data = None
	
	
	def __init__(self):
		ReportGenerator.__init__(self, "totals")
		self.data = {}
		
	def processEventInContext(self, resource, context, event, allocData):
		if resource not in self.data:
			if resource in self.overheadData:
				fileOverhead = self.plotter.createFile("%s-%s-overhead.dat" % (self.getId(), resource), "%s overhead" % resource)
			else:
				fileOverhead = None
			self.data[resource] = self.ResourceData(fileOverhead)
			
		if context.value not in self.data[resource].contexts:
			 fileTotals = self.plotter.createFile("%s-%s-%x.dat" % (self.getId(), resource, context.value), \
																		 "%s (%s)" % (resource, context.name))
			 self.data[resource].contexts[context.value] = self.ContextData(fileTotals)

		resourceData = self.data[resource]
		contextData = resourceData.contexts[context.value]
		stats = resourceData.stats
		
		# update X axis range
		if self.xrangeMin is None:
			self.xrangeMin = event.timestamp
		if self.xrangeMax  < event.timestamp:
			self.xrangeMax = event.timestamp
						
		if event.type == Event.Types.ALLOC:
			contextData.total += event.res_size
			# update statistics only when events aren't filtered by contexts
			if context.isMaskAll():
				stats.endLeaks.size += event.res_size
				stats.endLeaks.count += 1
				stats.endTotals.size += event.res_size
				stats.endTotals.count += 1
				if stats.endLeaks.size > stats.peakLeaks.size:
					stats.peakLeaks.size = stats.endLeaks.size
					stats.peakLeaks.count = stats.endLeaks.count
					stats.peakTotals.size = stats.endTotals.size
					stats.peakTotals.count = stats.endTotals.count
					stats.peakTimestamp = event.timestamp
				# update overhead data
				if self.overheadData[resource]:
					resourceData.overhead += event.res_size + self.overheadData[resource]
							
		if event.type == Event.Types.FREE:
			contextData.total -= event.res_size
			# update statistics only when events aren't filtered by contexts
			if context.isMaskAll():
				stats.endLeaks.size -= event.res_size
				stats.endLeaks.count -= 1
				# update overhead data
				if self.overheadData[resource]:
					resourceData.overhead -= (event.res_size + self.overheadData[resource])
			
		contextData.fileTotals.write(event.timestamp, contextData.total)

		if context.isMaskAll() and self.data[resource].fileOverhead:
			self.data[resource].fileOverhead.write(event.timestamp, resourceData.overhead)

		# update the Y axis range
		if contextData.total > self.yrangeMax:
			self.yrangeMax = contextData.total
		if resourceData.overhead > self.yrangeMax:
			self.yrangeMax = resourceData.overhead


	def finish(self):
		# Check if the gathered data is not empty
		if self.yrangeMax == 0:		
			print >> sys.stderr, "ERROR: Either the input file does not contain any events "\
			                     "or no events are matching the specified filter."
			self.plotter.cleanup()
			sys.exit(0)
	
		# increase Y range, so top graph isn't hidden beyond the axis	
		self.yrangeMax = self.yrangeMax * 105 / 100
		
		# number of graphs (without counting overhead data)
		ngraphs = 0

		# add the collected data to the graph
		for resource in self.data:
			resourceData = self.data[resource]
			for context in resourceData.contexts:
				self.plotter.addGraph(resourceData.contexts[context].fileTotals, "1", "2", "column(2)")
				ngraphs += 1

			if self.data[resource].fileOverhead:
				self.plotter.addGraph(resourceData.fileOverhead, "1", "2", "column(2)")

			timestamp = resourceData.stats.peakTimestamp
			file = self.plotter.createFile("%s-%s-peak.dat" % (self.getId(), resource), "%s (peak:%s)\n" % (resource, Timestamp.toString(timestamp)))
			file.write(timestamp, self.yrangeMin)
			file.write(timestamp, self.yrangeMax)
			self.plotter.addGraph(file, "1", "2", "column(2)")
			
		#	
		# generate gnuplot configuration file:
		#
		self.plotter.create()
		self.plotter.setTitle("Amount of non-freed allocations")
		
		self.plotter.setAxisX("time (secs)", self.xrangeMin, self.xrangeMax)
		self.plotter.setAxisY("size", self.yrangeMin, self.yrangeMax, "%.1s%c")
			
		self.plotter.setStyle("data lines")
		
		# Write summary report
		
		# define table headers
		table = self.plotter.createTable(1, 1)
		# resource name column
		table.addColumn(10)
		# snapshot name column
		table.addColumn(5)
		# total allocation count
		table.addColumn(8)
		# total allocation size
		table.addColumn(10)
		# leaked allocation count
		table.addColumn(8)
		# leaked allocation size
		table.addColumn(10)

		table.setText(1, 0, "Resource", "center")
		table.setText(1, 1, "State", "center")

		table.setText(0, 2, "Total", "center")
		table.setText(0, 3, "Total", "center")
		table.setText(1, 2, "count", "center")
		table.setText(1, 3, "size", "center")

		table.setText(0, 4, "Non-freed", "center")
		table.setText(0, 5, "Non-freed", "center")
		table.setText(1, 4, "count", "center")
		table.setText(1, 5, "size", "center")
		
		# write summary data
		resourceIndex = 3
		for resource in self.data:
			stats = self.data[resource].stats
			table.setText(resourceIndex, 0, resource, "left")
			table.setText(resourceIndex, 1, "peak", "center")
			table.setText(resourceIndex, 2, "%d" % stats.peakTotals.count)
			table.setText(resourceIndex, 3, "%d" % stats.peakTotals.size)
			table.setText(resourceIndex, 4, "%d" % stats.peakLeaks.count)
			table.setText(resourceIndex, 5, "%d" % stats.peakLeaks.size)

			resourceIndex += 1
			table.setText(resourceIndex, 1, "end", "center")
			table.setText(resourceIndex, 2, "%d" % stats.endTotals.count)
			table.setText(resourceIndex, 3, "%d" % stats.endTotals.size)
			table.setText(resourceIndex, 4, "%d" % stats.endLeaks.count)
			table.setText(resourceIndex, 5, "%d" % stats.endLeaks.size)
			
			resourceIndex += 2
		
		# Reserve space at the bottom for leak data
		bmargin = ngraphs + 9
		if bmargin < 9 + table.rows:
			bmargin = 9 + table.rows
		if bmargin < 15:
			bmargin = 15
		self.plotter.setBMargin(bmargin)
		# plot the data files
		self.plotter.plot()

# /class TotalsGenerator		
				
				
		
class Processor:
	"""
	This class processes the resource, context, events registering methods 
	and calls report generator hooks.
	"""
	
	class Index:
		"""
		This class is used to index resources by their identifiers. It's 
		used to minimize event lookups by resource identifier times.
		"""
		timestamp = 0
		size = 0
		refCount = 0
		
		def __init__(self, timestamp, size):
			self.timestamp = timestamp
			self.size = size
			self.refCount = 1
	# /class Index
	
	# context list
	contexts = None
	
	# resource list
	resources = None

	# report generators
	generators = None
	
	# event index used to track resource reference counting mechanism
	eventIndex = None
	
	# last timestamp/index to check event order
	lastIndex = 0
	lastTimestamp = 0
	
	def __init__(self):
		self.contexts = [Context(Context.MASK_ALL, "all allocations")]
		self.resources = {}
		self.generators = []
		self.eventIndex = {}
		
	def addGenerator(self, generator):
		"Adds a report generator"
		self.generators.append(generator)

	def isEventInRange(self, event):
		"Checks if the event matches the filters specified in Options."
		for filter in Options.filters:
			if not filter.matchesEvent(event):
				return False
		return True
	
	def processEvent(self, resource, event, allocData = None):
		"Processes the event in report generators"
		# check if events are properly ordered
		if self.lastTimestamp > event.timestamp or (self.lastTimestamp == event.timestamp and self.lastIndex > event.index):
			print >> sys.stderr, "ERROR: older event follows newer one in source file at index %d.\n" % event.index
			print >> sys.stderr, "To force correct event ordering in source file run sp-rtrace-postproc -i <source file> | rtrace-timeline <options>"
			sys.exit(2)

		self.lastTimestamp = event.timestamp
		self.lastIndex = event.index
				
		# check if the event matches the specified filters
		if not self.isEventInRange(event):
			return
		
		# call processXX calls for every context in all generators
		for context in self.contexts:
			if not event.matchContext(context):
				continue
			for generator in self.generators:
				generator.processEventInContext(resource.type, context, event, allocData)
	
	def registerAlloc(self, index, context, timestamp, res_type, res_id, res_size):
		"Registers resource allocation"
		if res_type is None:
			res_type = self.resources.keys()[0]
		else:
			if Options.filterResource is not None and Options.filterResource != res_type:
				return
		if res_type not in self.resources:
			print >> sys.stderr, "Unknown resource type: %s" % res_type
			sys.exit(2)
		resource = self.resources[res_type]
		
		# process reference counting if necessary
		if resource.refCounted:
			if res_id in self.eventIndex:
				self.eventIndex[res_id].refCount += 1
				return
				
		# create a new event
		event = Event(Event.Types.ALLOC, index, context, timestamp, res_id, res_size)
		
		# register the allocation
		self.eventIndex[res_id] = self.Index(timestamp, res_size);
		
		self.processEvent(resource, event)

		
	def registerFree(self, index, context, timestamp, res_type, res_id):
		"Registers resource deallocation"
		if res_type is None:
			res_type = self.resources.keys()[0]
		else:
			if Options.filterResource is not None and Options.filterResource != res_type:
				return
		if res_type not in self.resources:
			print >> sys.stderr, "Unknown resource type: %s" % res_type
			sys.exit(2)
		resource = self.resources[res_type]

		# process only the deallocation events for resources allocated in the scope
		if res_id not in self.eventIndex:
			return

		ievent = self.eventIndex[res_id]

		# process reference counting if necessary
		if resource.refCounted:
			ievent.refCount -= 1
			if ievent.refCount > 0:
				return

		# create a new event
		event = Event(Event.Types.FREE, index, context, timestamp, res_id, ievent.size)

		# undergister the allocation
		del self.eventIndex[res_id]

		self.processEvent(resource, event, ievent)

		
	def registerContext(self, value, name):
		"Registers context declaration"
		if len(self.contexts == 1):
			contexts.append(Context(Context.MASK_NONE, "no contexts"))
		self.contexts.append(Context(value, name))
		
	def registerResource(self, resource, refCounted = True):
		"Registers tracked resource"
		if Options.filterResource is None or Options.filterResource == resource:
			self.resources[resource] = Resource(resource, refCounted)
			
	def finishReports(self):
		"Finishes the reports"
		for generator in self.generators:
			generator.finish()
	
	def initialize(self):
		"Initailizes generators"
		for generator in self.generators:
			generator.initialize()
	
#/class Processor	
	
class Parser:
	"""
	This class parses the sp-rtrace format log file and calls the assigned processor
	to produce the required report file.
	"""
	processor = None
	reAlloc = re.compile("^([0-9]+)\.(?: @([0-9a-fA-F]+)|) [^[]*\[([^\]]+)\][^(<]+(?:<([^>]+)>|)\(([^)]+)\) = (0x[a-fA-F0-9]+)(.*)$")
	reFree = re.compile("^([0-9]+)\.(?: @([0-9a-fA-F]+)|) [^[]*\[([^\]]+)\][^(<]+(?:<([^>]+)>|)\((0x[a-fA-F0-9]+)\)$")
	reResource = re.compile("\<([0-9a-z]+)\> : ([^ ]+) \(([^\)]+)\)")
	reContext = re.compile("^\@ ([0-9a-fA-F]+) : (.*)$")
	
	# event list
	events = None
	# context list
	contexts = None
	# event processor
	processor = None
	
	def __init__(self, processor):
		self.events = {}
		self.contexts = []
		self.processor = processor
		
	def read(self, stream):
		"Reads and parses the input stream"
		for line in stream:
			# don't attempt to parse backtrace records
			if line[0] == '\t':
				continue
			#
			match = self.reAlloc.match(line)
			if match:
				context = match.group(2)
				if context is None:
					context = 0
				self.processor.registerAlloc(int(match.group(1)), context, Timestamp.fromString(match.group(3)), match.group(4), match.group(6), int(match.group(5)))
				continue
			match = self.reFree.match(line)
			if match:
				context = match.group(2)
				if context is None:
					context = 0
				self.processor.registerFree(int(match.group(1)), context, Timestamp.fromString(match.group(3)), match.group(4), match.group(5))
				continue
			match = self.reResource.match(line)
			if match:
				self.processor.registerResource(match.group(2))
				continue
			match = self.reContext.match(line)
			if match:
				self.processor.registerContext(int(match.group(1), 16), match.group(2))
				continue
			
		# sort the events by timestamp/index
#		for resource in self.events.keys():
#			self.events[resource] = sorted(self.events[resource], key = operator.attrgetter("index"))
#			self.events[resource] = sorted(self.events[resource], key = operator.attrgetter("timestamp"))
			
		
# /class Parser	
	

class Options:
	"""
	This class contains options parser implementation.
	"""

	class Fonts:
		NORMAL = "LiberationSans"
		ITALIC = "LiberationSans-Italic"
		BOLDITALIC = "LiberationSans-BoldItalic"
	# /class Fonts

	GDFONTPATH = "/usr/share/fonts/truetype/ttf-liberation"

		
	streamIn = sys.stdin
	# output filename
	outFilename = None
	# the output file extension
	outExtension = None
	# time slice value for activity report
	slice = None
	
	# true when png output is requested
	isPng = False
	
	#
	fonts = Fonts()
	
	# filter list
	filters = []
	# filter list textual interpretation
	filterString = None
	# the resource to filter
	filterResource = None
	
	# the output scaling factor
	scaleX = 1
	scaleY = 1
	
	def parse(argv):
		"Parses the command line arguments and initializes options."
		try:
			opts, args = getopt.gnu_getopt(argv, "tlahsco:i:S:ew", 
										["totals", 
										 "lifetime",
										 "activity", 
										 "in=",
										 "out=",
										 "slice=",
										 "eps",
										 "wxt",
										 "histogram-count",
										 "histogram-size",
										 "scale=",
										 "scalex=",
										 "scaley=",
										 "filter-size=",
										 "filter-time=",
										 "filter-index=",
										 "filter-context=",
										 "filter-resource=",
										 "help"])
		except getopt.GetoptError, err:
			print >> sys.stderr, str(err) 
			Options.displayUsage()
			sys.exit(2)
		
		processor = Processor()
		parser = Parser(processor)
		terminal = None
		
		for opt, val in opts:
			if opt == "-t" or opt == "--totals":
				processor.addGenerator(TotalsGenerator())
				continue
				
			if opt == "-l" or opt == "--lifetime":
				#processors.append(LifetimeProcessor(parser))
				continue
				
			if opt == "-a" or opt == "--activity":
				processor.addGenerator(ActivityGenerator())
				continue

			if opt == "-c" or opt == "--histogram-count":
				#processors.append(HistogramProcessor(parser, "count"))
				continue

			if opt == "-s" or opt == "--histogram-size":
				#processors.append(HistogramProcessor(parser, "size"))
				continue
				
			if opt == "-i" or opt == "--in":
				Options.streamIn = open(val, "r")
				continue
				
			if opt == "-o" or opt == "--out":
				Options.outFilename = val
				continue
			
			if opt == "-S" or opt == "--slice":
				Options.slice = int(val)
				continue
				
			if opt == "-e" or opt == "--eps":
				terminal = EpsTerminal()
				Options.outExtension = ".eps"
				continue
			
			if opt == "-w" or opt == "--wxt":
				terminal = WxtTerminal()
				continue
				
			if opt == "--scale":
				Options.scaleX = float(val)
				Options.scaleY = float(val)
				continue

			if opt == "--scalex":
				Options.scaleX = float(val)
				continue

			if opt == "--scaley":
				Options.scaleY = float(val)
				continue
				
			if opt == "--filter-size":
				match = re.match("([0-9kmKM]*)-([0-9kmKM]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid size filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("size", val)
				min = Options.parseSize(match.group(1))
				max = Options.parseSize(match.group(2))
				if min is not None:
					Options.filters.append(MinSizeFilter(min))
				if max is not None:
					Options.filters.append(MaxSizeFilter(max))
				continue
				
			if opt == "--filter-time":
				match = re.match("([0-9:.+]*)-([0-9:.+]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid timestamp filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("time", val)
				start = Options.parseTime(match.group(1))
				end = Options.parseTime(match.group(2))
				if start is not None:
					Options.filters.append(start > 0 and MinTimeFilter(start) or MinTimeOffsetFilter(-start))
				if end is not None:
					Options.filters.append(end > 0 and MaxTimeFilter(end) or MaxTimeOffsetFilter(-end))
				continue
				
			if opt == "--filter-index":
				match = re.match("([0-9]*)-([0-9]*)", val)
				if match is None:
					print >> sys.stderr, "Invalid size filter value: %s" % val
					Options.displayUsage()
					sys.exit(2)
				Options.updateFilter("index", val)
				min = Options.parseSize(match.group(1))
				max = Options.parseSize(match.group(2))
				if min is not None:
					Options.filters.append(MinIndexFilter(min))
				if max is not None:
					Options.filters.append(MaxIndexFilter(max))
				continue
			
			if opt == "--filter-context":
				Options.updateFilter("context", val)
				Options.filters.append(ContextFilter(int(val, 16)))
				continue
				
			if opt == "--filter-resource":
				Options.updateFilter("resource", val)
				Options.filterResource = val
				continue 
			
			if opt == "-h" or opt == "--help":
				Options.displayUsage()
				sys.exit(0)
				
		if len(processor.generators) < 1:
			print >> sys.stderr, "No report type specified."
			Options.displayUsage()
			sys.exit(2)
		
		# set the output terminal	
		if terminal is None:
			terminal = PngTerminal()
			Options.outExtension = ".png"

		Options.terminal = terminal

		return parser, processor

			
	def parseSize(text):
		"Parses filter size value"
		if text == "":
			return None
		match = re.match("([0-9]+)([kmKM]?)", text)
		if match is None:
			return None
		mod = 1
		if match.group(2).upper() == "K":
			mod = 1024
		if match.group(2).upper() == "M":
			mod = 1024 * 1024
		return int(match.group(1)) * mod

	
	def parseTime(text):
		"Parses filter time value"
		match = re.match("([+]|)(?:([0-9]+):|)(?:([0-9]+):|)(?:([0-9]+)|)(?:\.([0-9]+)|)", text)
		if match is None:
			return None
		timestamp = 0
		print >> sys.stderr, "1:%s, 2:%s, 3:%s, 4:%s, 5:%s" % (match.group(1), match.group(2), match.group(3), match.group(4), match.group(5))
		if match.group(2) is not None:
			timestamp += int(match.group(2)) *  60 * 1000
		if match.group(3) is not None:
			timestamp *= 60
			timestamp += int(match.group(3)) * 60 * 1000
		if match.group(4) is not None:
			timestamp += int(match.group(4)) * 1000
		if match.group(5) is not None:
			timestamp += int(match.group(5).ljust(3, '0'))
		return match.group(1) and -timestamp or timestamp
	
	def updateFilter(filter, value):
		if Options.filterString is None:
			Options.filterString = ""
		else:
			Options.filterString += "; "
		Options.filterString += "%s=%s" % (filter, value)
	
	def displayUsage():
		print \
"""
Usage:
  rtrace-timeline <options>
  Where <options> are:
    -t         generate report of total resource allocations and
               non-free resources.
    -l         generate report of resource life times.
    -a         generate report of resource allocation/deallocation
               activity.
    -c         generate allocation count per resource size histogram.
    -s         generate total allocation size per resource size histogram.
    -S <msec>  the time slice for acivity report. By default it's 1/20th
               of the total time period (X axis range).
    -e         generate postscript (eps) file (png file is generated by default).
    -w         display interactive report window.
    -i <file>  input file.
    -o <file>  output file.
    
    --scale=<value>
    --scalex=<value>
    --scaley=<value>
        Scales the output image by the specified factor. The scale
        option affects both axis while scalex and scaley options
        affects X and Y axis respectively.

    --filter-<type>=[<value1>]-[<value2>]
        Sets the event filter where filter type can be:
          <size>  - filters events by allocation size. The size parameter
                    accepts postfix 'k' or 'm' specifying kilobytes or
                    megabytes. Filter examples: 
                      100-200  : from 100 to 200 bytes
                      10k-     : greater than 10 kbytes
                      -1m      : less than 1 mbyte
          <index> - filters events by their index. 
          <time>  - filters events by allocation/deallocation timestamp.
                    The timestamp format is [+][HH:][MM:][SS][.sss] where
                    HH - hours, MM - minutes, SS - seconds, sss - milliseconds
                    and '+' specifies relative timestamp. Relative timestamps
                    are counted either from the report beginning (the filter 
                    start value) or from the first event passing previous 
                    filters (the filter end value). Filter examples: 
                      10.5-12       : from 10.5 seconds to 12 seconds
                      10:00-+30     : from 10 minutes to 10 minutes 30 seconds
                      +1:00-+1:00   : from 1 minute since log start to 1 minute 
                                      duration 
                            
    Note that it's possible to generate multiple reports at the same time by
    specifying more than one report generation option (-t, -l -a). In this 
    mode output file (-o) should be always specified and the report filenames
    will have the follwing format:
      <filename>-<totals|activity|lifetime>.<eps|png> 
         where <filename> is the specified output file.                      
"""

		
	# static method definitions
	parse = staticmethod(parse)
	displayUsage = staticmethod(displayUsage)
	parseSize = staticmethod(parseSize)
	parseTime = staticmethod(parseTime)
	updateFilter = staticmethod(updateFilter)
# /class Options
	


# main()

# parse the command line options
parser, processor = Options.parse(sys.argv[1:])

# initialize processor and report generators
processor.initialize()

# read the input stream and prepare reports
parser.read(Options.streamIn)

# finish the reports
processor.finishReports()


